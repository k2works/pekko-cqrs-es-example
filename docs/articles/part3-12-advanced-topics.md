# ç¬¬3éƒ¨ ç¬¬12ç« ï¼šé«˜åº¦ãªãƒˆãƒ”ãƒƒã‚¯

## æœ¬ç« ã®ç›®çš„

åœ¨åº«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ç™ºå±•çš„ãªæ©Ÿèƒ½ã¨å°†æ¥ã®æ‹¡å¼µã«ã¤ã„ã¦å­¦ã³ã¾ã™ï¼š

- **åœ¨åº«äºˆæ¸¬**: æ©Ÿæ¢°å­¦ç¿’ã‚’ä½¿ç”¨ã—ãŸéœ€è¦äºˆæ¸¬ã¨è‡ªå‹•ç™ºæ³¨
- **ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œ**: è¤‡æ•°ä¼æ¥­ã§ã®å…±æœ‰åˆ©ç”¨ã‚’å¯èƒ½ã«ã™ã‚‹ãƒ†ãƒŠãƒ³ãƒˆåˆ†é›¢
- **ã‚°ãƒ­ãƒ¼ãƒãƒ«å±•é–‹**: ãƒãƒ«ãƒãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æœ€é©åŒ–

ã“ã‚Œã‚‰ã®é«˜åº¦ãªãƒˆãƒ”ãƒƒã‚¯ã¯ã€åœ¨åº«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’ã•ã‚‰ã«ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã€ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã‚’é«˜ã‚ã‚‹ãŸã‚ã®ç™ºå±•çš„ãªæ©Ÿèƒ½ã§ã™ã€‚

## 12.1 åœ¨åº«äºˆæ¸¬

### 12.1.1 éå»ã®è²©å£²ãƒ‡ãƒ¼ã‚¿åˆ†æ

åœ¨åº«äºˆæ¸¬ã‚’è¡Œã†ã«ã¯ã€ã¾ãšéå»ã®å—æ‰•ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦å‚¾å‘ã‚’æŠŠæ¡ã—ã¾ã™ã€‚

**æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ**

```scala
// modules/query/interface-adapter/src/main/scala/adapters/analytics/InventoryTimeSeriesAnalyzer.scala
package adapters.analytics

import domain.model._
import adapters.dao.InventoryHistoryDao
import scala.concurrent.{Future, ExecutionContext}
import java.time.{LocalDate, DayOfWeek}

class InventoryTimeSeriesAnalyzer(
  historyDao: InventoryHistoryDao
)(implicit ec: ExecutionContext) {

  /**
   * æ—¥æ¬¡å—æ‰•ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ
   *
   * @param productId å•†å“ID
   * @param startDate é–‹å§‹æ—¥
   * @param endDate çµ‚äº†æ—¥
   * @return æ—¥æ¬¡ã®å…¥åº«æ•°ãƒ»å‡ºåº«æ•°ã®ãƒªã‚¹ãƒˆ
   */
  def analyzeDailyTransactions(
    productId: ProductId,
    startDate: LocalDate,
    endDate: LocalDate
  ): Future[List[DailyTransaction]] = {
    historyDao.aggregateByProductAndDate(productId, startDate, endDate).map { results =>
      results.map { case (date, receiveQty, shipQty) =>
        DailyTransaction(
          date = date,
          received = Quantity(receiveQty),
          shipped = Quantity(shipQty),
          net = Quantity(receiveQty - shipQty),
          dayOfWeek = date.getDayOfWeek
        )
      }
    }
  }

  /**
   * æ›œæ—¥åˆ¥ã®å‚¾å‘åˆ†æ
   *
   * æ›œæ—¥ã”ã¨ã®å¹³å‡å‡ºåº«æ•°ã‚’è¨ˆç®—
   */
  def analyzeWeekdayPattern(
    productId: ProductId,
    startDate: LocalDate,
    endDate: LocalDate
  ): Future[Map[DayOfWeek, Double]] = {
    analyzeDailyTransactions(productId, startDate, endDate).map { transactions =>
      transactions.groupBy(_.dayOfWeek).map { case (dayOfWeek, txs) =>
        val avgShipped = txs.map(_.shipped.value).sum.toDouble / txs.size.toDouble
        dayOfWeek -> avgShipped
      }
    }
  }

  /**
   * ç§»å‹•å¹³å‡ã®è¨ˆç®—
   *
   * @param window ç§»å‹•å¹³å‡ã®æœŸé–“ï¼ˆæ—¥æ•°ï¼‰
   */
  def calculateMovingAverage(
    productId: ProductId,
    startDate: LocalDate,
    endDate: LocalDate,
    window: Int = 7
  ): Future[List[(LocalDate, Double)]] = {
    analyzeDailyTransactions(productId, startDate, endDate).map { transactions =>
      val sorted = transactions.sortBy(_.date)

      sorted.sliding(window).map { windowTxs =>
        val avgShipped = windowTxs.map(_.shipped.value).sum.toDouble / window.toDouble
        (windowTxs.last.date, avgShipped)
      }.toList
    }
  }

  /**
   * å­£ç¯€æ€§ã®æ¤œå‡º
   *
   * æœˆã”ã¨ã®å‡ºåº«å‚¾å‘ã‚’åˆ†æ
   */
  def detectSeasonality(
    productId: ProductId,
    startDate: LocalDate,
    endDate: LocalDate
  ): Future[Map[Int, Double]] = {
    analyzeDailyTransactions(productId, startDate, endDate).map { transactions =>
      transactions.groupBy(_.date.getMonthValue).map { case (month, txs) =>
        val avgShipped = txs.map(_.shipped.value).sum.toDouble / txs.size.toDouble
        month -> avgShipped
      }
    }
  }
}

final case class DailyTransaction(
  date: LocalDate,
  received: Quantity,
  shipped: Quantity,
  net: Quantity,
  dayOfWeek: DayOfWeek
)
```

**SQLå®Ÿè£…ï¼ˆDAOï¼‰**

```scala
// modules/query/interface-adapter/src/main/scala/adapters/dao/InventoryHistoryDao.scala
package adapters.dao

import slick.jdbc.PostgresProfile.api._
import scala.concurrent.{Future, ExecutionContext}
import java.time.LocalDate

class InventoryHistoryDao(db: Database)(implicit ec: ExecutionContext) {

  /**
   * å•†å“ãƒ»æ—¥ä»˜åˆ¥ã®å—æ‰•é›†è¨ˆ
   */
  def aggregateByProductAndDate(
    productId: ProductId,
    startDate: LocalDate,
    endDate: LocalDate
  ): Future[List[(LocalDate, Int, Int)]] = {
    val query = sql"""
      SELECT
        DATE(å—æ‰•æ—¥æ™‚) AS æ—¥ä»˜,
        COALESCE(SUM(CASE WHEN å—æ‰•åŒºåˆ† = 'å…¥åº«' THEN å—æ‰•æ•°é‡ ELSE 0 END), 0) AS å…¥åº«æ•°,
        COALESCE(SUM(CASE WHEN å—æ‰•åŒºåˆ† = 'å‡ºåº«' THEN å—æ‰•æ•°é‡ ELSE 0 END), 0) AS å‡ºåº«æ•°
      FROM å—æ‰•å±¥æ­´
      WHERE å•†å“ID = ${productId.value}
        AND DATE(å—æ‰•æ—¥æ™‚) >= ${startDate}
        AND DATE(å—æ‰•æ—¥æ™‚) <= ${endDate}
      GROUP BY DATE(å—æ‰•æ—¥æ™‚)
      ORDER BY DATE(å—æ‰•æ—¥æ™‚)
    """.as[(LocalDate, Int, Int)]

    db.run(query).map(_.toList)
  }
}
```

### 12.1.2 æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹éœ€è¦äºˆæ¸¬

ç°¡æ˜“çš„ãªç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦éœ€è¦äºˆæ¸¬ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

**éœ€è¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«**

```scala
// modules/query/interface-adapter/src/main/scala/adapters/ml/DemandForecastModel.scala
package adapters.ml

import domain.model._
import scala.math._
import java.time.LocalDate

class DemandForecastModel {

  /**
   * å˜ç´”ãªç·šå½¢å›å¸°ã«ã‚ˆã‚‹éœ€è¦äºˆæ¸¬
   *
   * y = a + b*x
   * - y: äºˆæ¸¬å‡ºåº«æ•°
   * - x: æ—¥æ•°ï¼ˆåŸºæº–æ—¥ã‹ã‚‰ã®çµŒéæ—¥æ•°ï¼‰
   * - a: åˆ‡ç‰‡
   * - b: å‚¾ã
   */
  def forecast(
    historicalData: List[DailyTransaction],
    forecastDays: Int
  ): List[ForecastResult] = {
    require(historicalData.nonEmpty, "Historical data must not be empty")

    // æœ€å°äºŒä¹—æ³•ã§a, bã‚’è¨ˆç®—
    val baseDate = historicalData.head.date
    val dataPoints = historicalData.map { tx =>
      val x = baseDate.until(tx.date, java.time.temporal.ChronoUnit.DAYS).toDouble
      val y = tx.shipped.value.toDouble
      (x, y)
    }

    val (slope, intercept) = calculateLinearRegression(dataPoints)

    // äºˆæ¸¬
    val lastDate = historicalData.last.date
    (1 to forecastDays).map { day =>
      val forecastDate = lastDate.plusDays(day)
      val x = baseDate.until(forecastDate, java.time.temporal.ChronoUnit.DAYS).toDouble
      val predicted = intercept + slope * x

      ForecastResult(
        date = forecastDate,
        predictedDemand = Quantity(max(0, predicted.toInt)), // è² ã®å€¤ã¯0ã«
        confidenceInterval = calculateConfidenceInterval(dataPoints, slope, intercept, x)
      )
    }.toList
  }

  /**
   * æœ€å°äºŒä¹—æ³•ã«ã‚ˆã‚‹ç·šå½¢å›å¸°
   *
   * @return (å‚¾ã, åˆ‡ç‰‡)
   */
  private def calculateLinearRegression(dataPoints: List[(Double, Double)]): (Double, Double) = {
    val n = dataPoints.size.toDouble
    val sumX = dataPoints.map(_._1).sum
    val sumY = dataPoints.map(_._2).sum
    val sumXY = dataPoints.map { case (x, y) => x * y }.sum
    val sumX2 = dataPoints.map { case (x, _) => x * x }.sum

    val slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX)
    val intercept = (sumY - slope * sumX) / n

    (slope, intercept)
  }

  /**
   * ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
   *
   * æ¨™æº–èª¤å·®ã‚’ä½¿ç”¨ã—ã¦95%ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—
   */
  private def calculateConfidenceInterval(
    dataPoints: List[(Double, Double)],
    slope: Double,
    intercept: Double,
    x: Double
  ): ConfidenceInterval = {
    val predicted = intercept + slope * x

    // æ®‹å·®ã®è¨ˆç®—
    val residuals = dataPoints.map { case (xi, yi) =>
      val yPredicted = intercept + slope * xi
      yi - yPredicted
    }

    // æ¨™æº–èª¤å·®
    val standardError = sqrt(residuals.map(r => r * r).sum / (dataPoints.size - 2))

    // 95%ä¿¡é ¼åŒºé–“ï¼ˆtåˆ†å¸ƒã®ä»£ã‚ã‚Šã«ç°¡æ˜“çš„ã«1.96ã‚’ä½¿ç”¨ï¼‰
    val margin = 1.96 * standardError

    ConfidenceInterval(
      lower = Quantity(max(0, (predicted - margin).toInt)),
      upper = Quantity((predicted + margin).toInt)
    )
  }

  /**
   * ç§»å‹•å¹³å‡ã«ã‚ˆã‚‹éœ€è¦äºˆæ¸¬ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
   */
  def forecastWithMovingAverage(
    historicalData: List[DailyTransaction],
    forecastDays: Int,
    window: Int = 7
  ): List[ForecastResult] = {
    require(historicalData.size >= window, s"Historical data must have at least $window days")

    // ç›´è¿‘windowæ—¥é–“ã®å¹³å‡ã‚’å–å¾—
    val recentAvg = historicalData.takeRight(window).map(_.shipped.value).sum.toDouble / window.toDouble

    val lastDate = historicalData.last.date
    (1 to forecastDays).map { day =>
      ForecastResult(
        date = lastDate.plusDays(day),
        predictedDemand = Quantity(recentAvg.toInt),
        confidenceInterval = ConfidenceInterval(
          lower = Quantity((recentAvg * 0.8).toInt),
          upper = Quantity((recentAvg * 1.2).toInt)
        )
      )
    }.toList
  }
}

final case class ForecastResult(
  date: LocalDate,
  predictedDemand: Quantity,
  confidenceInterval: ConfidenceInterval
)

final case class ConfidenceInterval(
  lower: Quantity,
  upper: Quantity
)
```

**äºˆæ¸¬ã®å®Ÿè¡Œã¨å¯è¦–åŒ–**

```scala
// modules/query/interface-adapter/src/main/scala/adapters/analytics/DemandForecastService.scala
package adapters.analytics

import domain.model._
import adapters.ml.{DemandForecastModel, ForecastResult}
import scala.concurrent.{Future, ExecutionContext}
import java.time.LocalDate

class DemandForecastService(
  timeSeriesAnalyzer: InventoryTimeSeriesAnalyzer,
  forecastModel: DemandForecastModel
)(implicit ec: ExecutionContext) {

  /**
   * éœ€è¦äºˆæ¸¬ã®å®Ÿè¡Œ
   *
   * @param productId å•†å“ID
   * @param forecastDays äºˆæ¸¬æ—¥æ•°
   * @param historicalDays å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹éå»ãƒ‡ãƒ¼ã‚¿æ—¥æ•°
   */
  def predict(
    productId: ProductId,
    forecastDays: Int = 30,
    historicalDays: Int = 90
  ): Future[ForecastReport] = {
    val endDate = LocalDate.now()
    val startDate = endDate.minusDays(historicalDays)

    for {
      // éå»ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
      historicalData <- timeSeriesAnalyzer.analyzeDailyTransactions(productId, startDate, endDate)

      // æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
      weekdayPattern <- timeSeriesAnalyzer.analyzeWeekdayPattern(productId, startDate, endDate)

      // å­£ç¯€æ€§åˆ†æ
      seasonality <- timeSeriesAnalyzer.detectSeasonality(productId, startDate, endDate)

      // éœ€è¦äºˆæ¸¬
      forecast = forecastModel.forecast(historicalData, forecastDays)

    } yield {
      ForecastReport(
        productId = productId,
        generatedAt = LocalDate.now(),
        historicalPeriod = (startDate, endDate),
        forecastPeriod = (endDate.plusDays(1), endDate.plusDays(forecastDays)),
        historicalData = historicalData,
        forecast = forecast,
        weekdayPattern = weekdayPattern,
        seasonality = seasonality,
        recommendations = generateRecommendations(forecast, historicalData)
      )
    }
  }

  /**
   * æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
   */
  private def generateRecommendations(
    forecast: List[ForecastResult],
    historicalData: List[DailyTransaction]
  ): List[String] = {
    val avgHistorical = historicalData.map(_.shipped.value).sum.toDouble / historicalData.size.toDouble
    val avgForecast = forecast.map(_.predictedDemand.value).sum.toDouble / forecast.size.toDouble

    val recommendations = scala.collection.mutable.ListBuffer.empty[String]

    // éœ€è¦å¢—åŠ ã®æ¤œå‡º
    if (avgForecast > avgHistorical * 1.2) {
      recommendations += s"éœ€è¦å¢—åŠ ãŒäºˆæ¸¬ã•ã‚Œã¾ã™ï¼ˆéå»å¹³å‡: ${avgHistorical.toInt}å€‹/æ—¥ â†’ äºˆæ¸¬å¹³å‡: ${avgForecast.toInt}å€‹/æ—¥ï¼‰ã€‚åœ¨åº«è£œå……ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
    }

    // éœ€è¦æ¸›å°‘ã®æ¤œå‡º
    if (avgForecast < avgHistorical * 0.8) {
      recommendations += s"éœ€è¦æ¸›å°‘ãŒäºˆæ¸¬ã•ã‚Œã¾ã™ï¼ˆéå»å¹³å‡: ${avgHistorical.toInt}å€‹/æ—¥ â†’ äºˆæ¸¬å¹³å‡: ${avgForecast.toInt}å€‹/æ—¥ï¼‰ã€‚éå‰°åœ¨åº«ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚"
    }

    // åœ¨åº«ä¸è¶³ãƒªã‚¹ã‚¯ã®æ¤œå‡º
    val maxForecast = forecast.map(_.predictedDemand.value).max
    if (maxForecast > avgHistorical * 1.5) {
      recommendations += s"éœ€è¦ãƒ”ãƒ¼ã‚¯ãŒäºˆæ¸¬ã•ã‚Œã¾ã™ï¼ˆæœ€å¤§: ${maxForecast}å€‹/æ—¥ï¼‰ã€‚å®‰å…¨åœ¨åº«ã‚’ç¢ºä¿ã—ã¦ãã ã•ã„ã€‚"
    }

    recommendations.toList
  }
}

final case class ForecastReport(
  productId: ProductId,
  generatedAt: LocalDate,
  historicalPeriod: (LocalDate, LocalDate),
  forecastPeriod: (LocalDate, LocalDate),
  historicalData: List[DailyTransaction],
  forecast: List[ForecastResult],
  weekdayPattern: Map[java.time.DayOfWeek, Double],
  seasonality: Map[Int, Double],
  recommendations: List[String]
)
```

### 12.1.3 è‡ªå‹•ç™ºæ³¨ã®å®Ÿè£…

éœ€è¦äºˆæ¸¬ã«åŸºã¥ã„ã¦è‡ªå‹•ç™ºæ³¨ã‚’ææ¡ˆã—ã¾ã™ã€‚

```scala
// modules/query/interface-adapter/src/main/scala/adapters/purchasing/AutoPurchaseRecommender.scala
package adapters.purchasing

import domain.model._
import adapters.analytics.{DemandForecastService, ForecastReport}
import adapters.dao.InventoryDao
import scala.concurrent.{Future, ExecutionContext}
import java.time.LocalDate

class AutoPurchaseRecommender(
  inventoryDao: InventoryDao,
  forecastService: DemandForecastService
)(implicit ec: ExecutionContext) {

  /**
   * è‡ªå‹•ç™ºæ³¨æ¨å¥¨ã®ç”Ÿæˆ
   *
   * @param productId å•†å“ID
   * @param leadTime ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼ˆæ—¥æ•°ï¼‰
   * @param safetyStockDays å®‰å…¨åœ¨åº«æ—¥æ•°
   */
  def recommend(
    productId: ProductId,
    leadTime: Int = 7,
    safetyStockDays: Int = 14
  ): Future[PurchaseRecommendation] = {
    for {
      // ç¾åœ¨ã®åœ¨åº«çŠ¶æ³ã‚’å–å¾—
      currentInventory <- inventoryDao.getTotalByProduct(productId)

      // éœ€è¦äºˆæ¸¬ã‚’å–å¾—
      forecast <- forecastService.predict(productId, forecastDays = leadTime + safetyStockDays)

    } yield {
      // äºˆæ¸¬æœŸé–“ä¸­ã®ç·éœ€è¦
      val totalDemand = forecast.forecast.map(_.predictedDemand.value).sum

      // å®‰å…¨åœ¨åº«
      val avgDailyDemand = totalDemand.toDouble / forecast.forecast.size.toDouble
      val safetyStock = (avgDailyDemand * safetyStockDays).toInt

      // ç™ºæ³¨ç‚¹
      val reorderPoint = (avgDailyDemand * leadTime).toInt + safetyStock

      // ç™ºæ³¨æ¨å¥¨æ•°é‡
      val recommendedOrderQty = if (currentInventory.value < reorderPoint) {
        // ç™ºæ³¨ç‚¹ã‚’ä¸‹å›ã£ã¦ã„ã‚‹å ´åˆã€å®‰å…¨åœ¨åº«ã¾ã§ã®è£œå……é‡ã‚’è¨ˆç®—
        val orderQty = reorderPoint - currentInventory.value + (avgDailyDemand * leadTime).toInt
        Some(Quantity(orderQty))
      } else {
        None
      }

      PurchaseRecommendation(
        productId = productId,
        currentInventory = currentInventory,
        avgDailyDemand = avgDailyDemand,
        reorderPoint = Quantity(reorderPoint),
        safetyStock = Quantity(safetyStock),
        leadTime = leadTime,
        recommendedOrderQty = recommendedOrderQty,
        urgency = calculateUrgency(currentInventory, reorderPoint, avgDailyDemand),
        forecast = forecast
      )
    }
  }

  /**
   * ç·Šæ€¥åº¦ã®è¨ˆç®—
   */
  private def calculateUrgency(
    currentInventory: Quantity,
    reorderPoint: Int,
    avgDailyDemand: Double
  ): PurchaseUrgency = {
    val daysUntilStockout = currentInventory.value.toDouble / avgDailyDemand

    if (daysUntilStockout < 3) PurchaseUrgency.Critical
    else if (daysUntilStockout < 7) PurchaseUrgency.High
    else if (currentInventory.value < reorderPoint) PurchaseUrgency.Medium
    else PurchaseUrgency.Low
  }
}

final case class PurchaseRecommendation(
  productId: ProductId,
  currentInventory: Quantity,
  avgDailyDemand: Double,
  reorderPoint: Quantity,
  safetyStock: Quantity,
  leadTime: Int,
  recommendedOrderQty: Option[Quantity],
  urgency: PurchaseUrgency,
  forecast: ForecastReport
)

sealed trait PurchaseUrgency
object PurchaseUrgency {
  case object Critical extends PurchaseUrgency  // 3æ—¥ä»¥å†…ã«åœ¨åº«åˆ‡ã‚Œ
  case object High extends PurchaseUrgency      // 7æ—¥ä»¥å†…ã«åœ¨åº«åˆ‡ã‚Œ
  case object Medium extends PurchaseUrgency    // ç™ºæ³¨ç‚¹ã‚’ä¸‹å›ã£ã¦ã„ã‚‹
  case object Low extends PurchaseUrgency       // åœ¨åº«ååˆ†
}
```

**è‡ªå‹•ç™ºæ³¨ã‚¢ãƒ©ãƒ¼ãƒˆã®å®Ÿè£…**

```scala
// apps/read-model-updater/src/main/scala/batch/AutoPurchaseBatch.scala
package batch

import domain.model._
import adapters.purchasing.{AutoPurchaseRecommender, PurchaseUrgency}
import notification.SlackNotifier
import org.apache.pekko.actor.typed.ActorSystem
import scala.concurrent.{Future, ExecutionContext}

class AutoPurchaseBatch(
  recommender: AutoPurchaseRecommender,
  productIds: List[ProductId]
)(implicit system: ActorSystem[_], ec: ExecutionContext) {

  /**
   * å…¨å•†å“ã®ç™ºæ³¨æ¨å¥¨ã‚’ãƒã‚§ãƒƒã‚¯
   */
  def runPurchaseCheck(): Future[List[PurchaseRecommendation]] = {
    Future.traverse(productIds) { productId =>
      recommender.recommend(productId)
    }.map { recommendations =>
      // ç™ºæ³¨ãŒå¿…è¦ãªå•†å“ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
      val needsOrder = recommendations.filter(_.recommendedOrderQty.isDefined)

      // ç·Šæ€¥åº¦åˆ¥ã«ã‚½ãƒ¼ãƒˆ
      val sorted = needsOrder.sortBy(_.urgency match {
        case PurchaseUrgency.Critical => 1
        case PurchaseUrgency.High => 2
        case PurchaseUrgency.Medium => 3
        case PurchaseUrgency.Low => 4
      })

      // Slackã«é€šçŸ¥
      if (sorted.nonEmpty) {
        system.log.info(s"Found ${sorted.size} products that need ordering")
        sorted.foreach(sendAlert)
      }

      sorted
    }
  }

  private def sendAlert(recommendation: PurchaseRecommendation): Unit = {
    val urgencyEmoji = recommendation.urgency match {
      case PurchaseUrgency.Critical => "ğŸš¨"
      case PurchaseUrgency.High => "âš ï¸"
      case PurchaseUrgency.Medium => "â„¹ï¸"
      case PurchaseUrgency.Low => "âœ…"
    }

    system.log.warn(
      s"$urgencyEmoji Auto-purchase recommendation: " +
      s"productId=${recommendation.productId.value}, " +
      s"currentInventory=${recommendation.currentInventory.value}, " +
      s"recommendedOrderQty=${recommendation.recommendedOrderQty.map(_.value).getOrElse(0)}, " +
      s"urgency=${recommendation.urgency}"
    )

    // Slacké€šçŸ¥ã®å®Ÿè£…ã¯11.3.4ã‚’å‚ç…§
  }
}
```

## 12.2 ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œ

### 12.2.1 ãƒ†ãƒŠãƒ³ãƒˆåˆ†é›¢æˆ¦ç•¥

è¤‡æ•°ä¼æ¥­ï¼ˆãƒ†ãƒŠãƒ³ãƒˆï¼‰ã§åœ¨åº«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’å…±æœ‰ã™ã‚‹å ´åˆã€ãƒ†ãƒŠãƒ³ãƒˆåˆ†é›¢æˆ¦ç•¥ãŒå¿…è¦ã§ã™ã€‚

**ãƒ†ãƒŠãƒ³ãƒˆåˆ†é›¢ã®3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**

| ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ | èª¬æ˜ | ãƒ¡ãƒªãƒƒãƒˆ | ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ |
|----------|------|---------|----------|
| **Database per Tenant** | ãƒ†ãƒŠãƒ³ãƒˆã”ã¨ã«å°‚ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ | å®Œå…¨ãªåˆ†é›¢ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ | é‹ç”¨ã‚³ã‚¹ãƒˆé«˜ã€ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¤‡é›‘ |
| **Schema per Tenant** | åŒä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã§å°‚ç”¨ã‚¹ã‚­ãƒ¼ãƒ | é©åº¦ãªåˆ†é›¢ã€ã‚³ã‚¹ãƒˆå‰Šæ¸› | ã‚¹ã‚­ãƒ¼ãƒç®¡ç†ãŒè¤‡é›‘ |
| **Shared Schema** | å…¨ãƒ†ãƒŠãƒ³ãƒˆã§åŒä¸€ã‚¹ã‚­ãƒ¼ãƒã€è¡Œãƒ¬ãƒ™ãƒ«åˆ†é›¢ | é‹ç”¨ã‚³ã‚¹ãƒˆæœ€å°ã€ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡çš„ | åˆ†é›¢ãŒå¼±ã„ã€ã‚¯ã‚¨ãƒªæ€§èƒ½ã«æ³¨æ„ |

ä»Šå›ã¯**Shared Schemaï¼ˆè¡Œãƒ¬ãƒ™ãƒ«åˆ†é›¢ï¼‰**ã‚’æ¡ç”¨ã—ã¾ã™ã€‚

### 12.2.2 ãƒ‡ãƒ¼ã‚¿ã®åˆ†é›¢ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

**ãƒ†ãƒŠãƒ³ãƒˆIDã®è¿½åŠ **

```sql
-- åœ¨åº«ãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ†ãƒŠãƒ³ãƒˆIDã‚’è¿½åŠ 
ALTER TABLE åœ¨åº« ADD COLUMN ãƒ†ãƒŠãƒ³ãƒˆID VARCHAR(50) NOT NULL DEFAULT 'default';

-- å—æ‰•å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ†ãƒŠãƒ³ãƒˆIDã‚’è¿½åŠ 
ALTER TABLE å—æ‰•å±¥æ­´ ADD COLUMN ãƒ†ãƒŠãƒ³ãƒˆID VARCHAR(50) NOT NULL DEFAULT 'default';

-- ãƒ†ãƒŠãƒ³ãƒˆåˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_åœ¨åº«_ãƒ†ãƒŠãƒ³ãƒˆID ON åœ¨åº«(ãƒ†ãƒŠãƒ³ãƒˆID);
CREATE INDEX idx_å—æ‰•å±¥æ­´_ãƒ†ãƒŠãƒ³ãƒˆID ON å—æ‰•å±¥æ­´(ãƒ†ãƒŠãƒ³ãƒˆID);

-- Row Level Securityï¼ˆPostgreSQLï¼‰
ALTER TABLE åœ¨åº« ENABLE ROW LEVEL SECURITY;

CREATE POLICY åœ¨åº«_tenant_isolation ON åœ¨åº«
  USING (ãƒ†ãƒŠãƒ³ãƒˆID = current_setting('app.current_tenant_id')::VARCHAR);

ALTER TABLE å—æ‰•å±¥æ­´ ENABLE ROW LEVEL SECURITY;

CREATE POLICY å—æ‰•å±¥æ­´_tenant_isolation ON å—æ‰•å±¥æ­´
  USING (ãƒ†ãƒŠãƒ³ãƒˆID = current_setting('app.current_tenant_id')::VARCHAR);
```

**ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®æ‹¡å¼µ**

```scala
// modules/command/domain/src/main/scala/domain/model/TenantId.scala
package domain.model

final case class TenantId(value: String) extends AnyVal {
  require(value.nonEmpty, "TenantId must not be empty")
  require(value.matches("^[a-zA-Z0-9_-]+$"), "TenantId must be alphanumeric")
}

// Inventoryã«ãƒ†ãƒŠãƒ³ãƒˆæƒ…å ±ã‚’è¿½åŠ 
final case class Inventory private (
  id: InventoryId,
  tenantId: TenantId,  // è¿½åŠ 
  warehouseCode: WarehouseCode,
  productId: ProductId,
  zoneNumber: ZoneNumber,
  quantityOnHand: Quantity,
  quantityReserved: Quantity,
  version: Version
) extends Entity {
  // ... ãƒ¡ã‚½ãƒƒãƒ‰ã¯å¤‰æ›´ãªã—
}
```

**ãƒ†ãƒŠãƒ³ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç®¡ç†**

```scala
// modules/infrastructure/src/main/scala/tenancy/TenantContext.scala
package tenancy

import domain.model.TenantId
import scala.concurrent.{Future, ExecutionContext}

/**
 * ãƒ†ãƒŠãƒ³ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
 *
 * ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¹ã‚³ãƒ¼ãƒ—ã§ãƒ†ãƒŠãƒ³ãƒˆIDã‚’ç®¡ç†
 */
object TenantContext {
  private val threadLocal = new ThreadLocal[TenantId]

  def set(tenantId: TenantId): Unit = {
    threadLocal.set(tenantId)
  }

  def get: Option[TenantId] = {
    Option(threadLocal.get())
  }

  def clear(): Unit = {
    threadLocal.remove()
  }

  def require: TenantId = {
    get.getOrElse(throw new IllegalStateException("TenantId not set in context"))
  }

  /**
   * ãƒ†ãƒŠãƒ³ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®šã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œ
   */
  def withTenant[T](tenantId: TenantId)(f: => T): T = {
    try {
      set(tenantId)
      f
    } finally {
      clear()
    }
  }

  /**
   * éåŒæœŸå‡¦ç†ç”¨
   */
  def withTenantAsync[T](tenantId: TenantId)(f: => Future[T])(implicit ec: ExecutionContext): Future[T] = {
    set(tenantId)
    f.andThen { case _ => clear() }
  }
}
```

**HTTPãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã§ã®ãƒ†ãƒŠãƒ³ãƒˆæŠ½å‡º**

```scala
// apps/command-api/src/main/scala/api/middleware/TenantMiddleware.scala
package api.middleware

import domain.model.TenantId
import tenancy.TenantContext
import org.apache.pekko.http.scaladsl.server.Directive1
import org.apache.pekko.http.scaladsl.server.Directives._
import org.apache.pekko.http.scaladsl.model.StatusCodes

object TenantMiddleware {

  /**
   * ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰ãƒ†ãƒŠãƒ³ãƒˆIDã‚’æŠ½å‡º
   *
   * X-Tenant-ID: tenant-abc
   */
  def extractTenant: Directive1[TenantId] = {
    optionalHeaderValueByName("X-Tenant-ID").flatMap {
      case Some(tenantIdStr) =>
        try {
          val tenantId = TenantId(tenantIdStr)
          TenantContext.set(tenantId)
          provide(tenantId)
        } catch {
          case _: IllegalArgumentException =>
            complete(StatusCodes.BadRequest, "Invalid tenant ID format")
        }

      case None =>
        complete(StatusCodes.BadRequest, "X-Tenant-ID header is required")
    }
  }

  /**
   * ãƒ†ãƒŠãƒ³ãƒˆèªè¨¼ï¼ˆç°¡æ˜“ç‰ˆï¼‰
   *
   * å®Ÿéš›ã®å®Ÿè£…ã§ã¯JWTãƒˆãƒ¼ã‚¯ãƒ³æ¤œè¨¼ãªã©ã‚’è¡Œã†
   */
  def authenticateTenant: Directive1[TenantId] = {
    extractTenant.flatMap { tenantId =>
      // ã“ã“ã§èªè¨¼ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
      // ä¾‹: JWTãƒˆãƒ¼ã‚¯ãƒ³ã®æ¤œè¨¼ã€ãƒ†ãƒŠãƒ³ãƒˆã®å­˜åœ¨ç¢ºèªãªã©

      provide(tenantId)
    }
  }
}
```

**DAOã§ã®ãƒ†ãƒŠãƒ³ãƒˆåˆ†é›¢**

```scala
// modules/query/interface-adapter/src/main/scala/adapters/dao/MultiTenantInventoryDao.scala
package adapters.dao

import domain.model._
import tenancy.TenantContext
import slick.jdbc.PostgresProfile.api._
import scala.concurrent.{Future, ExecutionContext}

class MultiTenantInventoryDao(db: Database)(implicit ec: ExecutionContext) {

  /**
   * ãƒ†ãƒŠãƒ³ãƒˆåˆ¥åœ¨åº«å–å¾—
   *
   * ãƒ†ãƒŠãƒ³ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è‡ªå‹•çš„ã«ãƒ•ã‚£ãƒ«ã‚¿
   */
  def findByProduct(productId: ProductId): Future[List[Inventory]] = {
    val tenantId = TenantContext.require

    val query = sql"""
      SELECT
        åœ¨åº«ID, å•†å“ID, å€‰åº«ã‚³ãƒ¼ãƒ‰, åŒºç”»ç•ªå·, ç¾åœ¨åº«æ•°, å¼•å½“æ¸ˆæ•°, ãƒãƒ¼ã‚¸ãƒ§ãƒ³
      FROM åœ¨åº«
      WHERE ãƒ†ãƒŠãƒ³ãƒˆID = ${tenantId.value}
        AND å•†å“ID = ${productId.value}
        AND å‰Šé™¤ãƒ•ãƒ©ã‚° = false
    """.as[(String, String, String, Int, Int, Int, Int)]

    db.run(query).map { results =>
      results.map { case (invId, prodId, whCode, zone, onHand, reserved, ver) =>
        Inventory(
          id = InventoryId(invId),
          tenantId = tenantId,
          productId = ProductId(prodId),
          warehouseCode = WarehouseCode(whCode),
          zoneNumber = ZoneNumber(zone),
          quantityOnHand = Quantity(onHand),
          quantityReserved = Quantity(reserved),
          version = Version(ver)
        )
      }.toList
    }
  }

  /**
   * PostgreSQL Row Level Securityã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
   */
  def findByProductWithRLS(productId: ProductId): Future[List[Inventory]] = {
    val tenantId = TenantContext.require

    // ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã‚’è¨­å®šã—ã¦RLSã‚’æœ‰åŠ¹åŒ–
    val setTenantId = sqlu"SET LOCAL app.current_tenant_id = ${tenantId.value}"

    val query = sql"""
      SELECT
        åœ¨åº«ID, å•†å“ID, å€‰åº«ã‚³ãƒ¼ãƒ‰, åŒºç”»ç•ªå·, ç¾åœ¨åº«æ•°, å¼•å½“æ¸ˆæ•°, ãƒãƒ¼ã‚¸ãƒ§ãƒ³
      FROM åœ¨åº«
      WHERE å•†å“ID = ${productId.value}
        AND å‰Šé™¤ãƒ•ãƒ©ã‚° = false
    """.as[(String, String, String, Int, Int, Int, Int)]

    db.run(setTenantId.andThen(query).transactionally).map { results =>
      // ... ãƒãƒƒãƒ”ãƒ³ã‚°å‡¦ç†
      List.empty
    }
  }
}
```

### 12.2.3 ãƒ†ãƒŠãƒ³ãƒˆã”ã¨ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

```scala
// modules/infrastructure/src/main/scala/tenancy/TenantConfigRepository.scala
package tenancy

import domain.model.TenantId
import scala.concurrent.{Future, ExecutionContext}

class TenantConfigRepository()(implicit ec: ExecutionContext) {

  /**
   * ãƒ†ãƒŠãƒ³ãƒˆåˆ¥è¨­å®šã®å–å¾—
   */
  def getConfig(tenantId: TenantId): Future[TenantConfig] = Future {
    // å®Ÿéš›ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—
    TenantConfig(
      tenantId = tenantId,
      name = s"Tenant ${tenantId.value}",
      features = TenantFeatures(
        inventoryForecast = true,
        autoPurchase = true,
        multiWarehouse = true
      ),
      limits = TenantLimits(
        maxWarehouses = 10,
        maxProducts = 10000,
        maxDailyTransactions = 5000
      ),
      customization = TenantCustomization(
        lowStockThreshold = 100,
        safetyStockDays = 14,
        leadTimeDays = 7
      )
    )
  }
}

final case class TenantConfig(
  tenantId: TenantId,
  name: String,
  features: TenantFeatures,
  limits: TenantLimits,
  customization: TenantCustomization
)

final case class TenantFeatures(
  inventoryForecast: Boolean,
  autoPurchase: Boolean,
  multiWarehouse: Boolean
)

final case class TenantLimits(
  maxWarehouses: Int,
  maxProducts: Int,
  maxDailyTransactions: Int
)

final case class TenantCustomization(
  lowStockThreshold: Int,
  safetyStockDays: Int,
  leadTimeDays: Int
)
```

## 12.3 ã‚°ãƒ­ãƒ¼ãƒãƒ«å±•é–‹

### 12.3.1 ãƒãƒ«ãƒãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤

åœ°ç†çš„ã«åˆ†æ•£ã—ãŸæ‹ ç‚¹ã§åœ¨åº«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’é‹ç”¨ã™ã‚‹å ´åˆã€ãƒãƒ«ãƒãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤ãŒå¿…è¦ã§ã™ã€‚

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦**

```plantuml
@startuml
!define RECTANGLE class

cloud "Asia-Pacific Region" as APRegion {
  RECTANGLE "Command API\n(Tokyo)" as CommandAP
  database "DynamoDB\n(ap-northeast-1)" as DynamoAP
  RECTANGLE "Query API\n(Tokyo)" as QueryAP
  database "PostgreSQL\n(RDS ap-northeast-1)" as PostgresAP
}

cloud "Europe Region" as EURegion {
  RECTANGLE "Command API\n(Frankfurt)" as CommandEU
  database "DynamoDB\n(eu-central-1)" as DynamoEU
  RECTANGLE "Query API\n(Frankfurt)" as QueryEU
  database "PostgreSQL\n(RDS eu-central-1)" as PostgresEU
}

cloud "US Region" as USRegion {
  RECTANGLE "Command API\n(Virginia)" as CommandUS
  database "DynamoDB\n(us-east-1)" as DynamoUS
  RECTANGLE "Query API\n(Virginia)" as QueryUS
  database "PostgreSQL\n(RDS us-east-1)" as PostgresUS
}

actor "Asia User" as UserAP
actor "EU User" as UserEU
actor "US User" as UserUS

UserAP --> CommandAP: æ›¸ãè¾¼ã¿ï¼ˆä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼‰
UserAP --> QueryAP: èª­ã¿å–ã‚Šï¼ˆä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼‰

UserEU --> CommandEU: æ›¸ãè¾¼ã¿ï¼ˆä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼‰
UserEU --> QueryEU: èª­ã¿å–ã‚Šï¼ˆä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼‰

UserUS --> CommandUS: æ›¸ãè¾¼ã¿ï¼ˆä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼‰
UserUS --> QueryUS: èª­ã¿å–ã‚Šï¼ˆä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼‰

DynamoAP -[dashed]-> DynamoEU: Global Table\nï¼ˆè‡ªå‹•ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
DynamoEU -[dashed]-> DynamoUS: Global Table
DynamoUS -[dashed]-> DynamoAP: Global Table

PostgresAP -[dashed]-> PostgresEU: Read Replica\nï¼ˆéåŒæœŸãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
PostgresEU -[dashed]-> PostgresUS: Read Replica
PostgresUS -[dashed]-> PostgresAP: Read Replica

note right of DynamoAP
  DynamoDB Global Tablesã«ã‚ˆã‚Š
  å„ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã§æ›¸ãè¾¼ã¿å¯èƒ½
  ï¼ˆãƒãƒ«ãƒãƒã‚¹ã‚¿ãƒ¼ï¼‰
end note

note right of PostgresAP
  Read Modelã¯å„ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã§
  ç‹¬ç«‹ã—ã¦æ›´æ–°
  ï¼ˆçµæœæ•´åˆæ€§ï¼‰
end note

@enduml
```

### 12.3.2 åœ°ç†çš„åˆ†æ•£ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æœ€é©åŒ–

**ãƒªãƒ¼ã‚¸ãƒ§ãƒ³åˆ¥ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**

```scala
// modules/infrastructure/src/main/scala/geo/RegionRouter.scala
package geo

import domain.model.WarehouseCode
import scala.concurrent.{Future, ExecutionContext}

class RegionRouter()(implicit ec: ExecutionContext) {

  /**
   * å€‰åº«ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æ±ºå®š
   */
  def getRegionForWarehouse(warehouseCode: WarehouseCode): Region = {
    warehouseCode.value match {
      case wh if wh.startsWith("WH-JP") => Region.AsiaPacific
      case wh if wh.startsWith("WH-EU") => Region.Europe
      case wh if wh.startsWith("WH-US") => Region.UnitedStates
      case _ => Region.AsiaPacific // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    }
  }

  /**
   * ãƒªãƒ¼ã‚¸ãƒ§ãƒ³åˆ¥ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå–å¾—
   */
  def getEndpointForRegion(region: Region): String = {
    region match {
      case Region.AsiaPacific => "https://inventory-api.ap-northeast-1.example.com"
      case Region.Europe => "https://inventory-api.eu-central-1.example.com"
      case Region.UnitedStates => "https://inventory-api.us-east-1.example.com"
    }
  }

  /**
   * æœ€å¯„ã‚Šã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’é¸æŠï¼ˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ™ãƒ¼ã‚¹ï¼‰
   */
  def selectNearestRegion(clientIp: String): Future[Region] = Future {
    // IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‹ã‚‰ã‚¸ã‚ªãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å–å¾—
    // å®Ÿéš›ã®å®Ÿè£…ã§ã¯MaxMind GeoIP2ãªã©ã‚’ä½¿ç”¨
    Region.AsiaPacific
  }
}

sealed trait Region
object Region {
  case object AsiaPacific extends Region
  case object Europe extends Region
  case object UnitedStates extends Region
}
```

**DynamoDB Global Tablesã®è¨­å®š**

```scala
// modules/infrastructure/src/main/scala/persistence/GlobalTableConfig.scala
package persistence

object GlobalTableConfig {

  /**
   * DynamoDB Global Tablesã®è¨­å®š
   *
   * aws dynamodb create-global-table \
   *   --global-table-name inventory-events \
   *   --replication-group \
   *     RegionName=ap-northeast-1 \
   *     RegionName=eu-central-1 \
   *     RegionName=us-east-1
   */
  val globalTableConfig = Map(
    "TableName" -> "inventory-events",
    "Regions" -> List(
      "ap-northeast-1",
      "eu-central-1",
      "us-east-1"
    )
  )
}
```

**ãƒªãƒ¼ã‚¸ãƒ§ãƒ³é–“ã®ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é…å»¶å¯¾ç­–**

```scala
// modules/infrastructure/src/main/scala/geo/ReplicationAwareReadModel.scala
package geo

import domain.model._
import scala.concurrent.{Future, ExecutionContext}
import scala.concurrent.duration._

class ReplicationAwareReadModel(
  localDao: InventoryDao,
  regionRouter: RegionRouter
)(implicit ec: ExecutionContext) {

  /**
   * ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é…å»¶ã‚’è€ƒæ…®ã—ãŸèª­ã¿å–ã‚Š
   *
   * 1. ãƒ­ãƒ¼ã‚«ãƒ«ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‹ã‚‰èª­ã¿å–ã‚Š
   * 2. ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã€ä»–ã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è©¦è¡Œ
   * 3. ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€çŸ­æ™‚é–“å¾…æ©Ÿå¾Œã«ãƒªãƒˆãƒ©ã‚¤
   */
  def findByIdWithReplication(
    inventoryId: InventoryId,
    maxRetries: Int = 3,
    retryDelay: FiniteDuration = 500.millis
  ): Future[Option[Inventory]] = {
    def retry(attemptsLeft: Int): Future[Option[Inventory]] = {
      localDao.findById(inventoryId).flatMap {
        case Some(inventory) =>
          Future.successful(Some(inventory))

        case None if attemptsLeft > 0 =>
          // ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é…å»¶ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€å¾…æ©Ÿå¾Œã«ãƒªãƒˆãƒ©ã‚¤
          Future {
            Thread.sleep(retryDelay.toMillis)
          }.flatMap(_ => retry(attemptsLeft - 1))

        case None =>
          Future.successful(None)
      }
    }

    retry(maxRetries)
  }
}
```

### 12.3.3 ã‚°ãƒ­ãƒ¼ãƒãƒ«å±•é–‹ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

**1. ãƒ‡ãƒ¼ã‚¿ã®å±€æ‰€æ€§ï¼ˆData Localityï¼‰**

```scala
// ãƒ‡ãƒ¼ã‚¿ã‚’åœ°ç†çš„ã«è¿‘ã„å ´æ‰€ã«é…ç½®
val inventory = Inventory(
  id = InventoryId("INV-JP-001"),
  tenantId = TenantId("tenant-jp"),
  warehouseCode = WarehouseCode("WH-JP-Tokyo"),  // æ±äº¬å€‰åº«
  // ... æ±äº¬ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã«é…ç½®
)
```

**2. èª­ã¿å–ã‚Šã®æœ€é©åŒ–**

- ãƒ­ãƒ¼ã‚«ãƒ«ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‹ã‚‰èª­ã¿å–ã‚Š
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆRedisï¼‰ã®æ´»ç”¨
- CDNã§ã®é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é…ä¿¡

**3. æ›¸ãè¾¼ã¿ã®æœ€é©åŒ–**

- ãƒãƒ«ãƒãƒã‚¹ã‚¿ãƒ¼æ§‹æˆï¼ˆDynamoDB Global Tablesï¼‰
- éåŒæœŸãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- ç«¶åˆè§£æ±ºæˆ¦ç•¥ï¼ˆLast-Write-Winsï¼‰

**4. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°**

```scala
// ãƒªãƒ¼ã‚¸ãƒ§ãƒ³é–“ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é…å»¶ã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
class ReplicationMonitor(
  metricsCollector: MetricsCollector
) {

  def recordReplicationLag(
    sourceRegion: Region,
    targetRegion: Region,
    lagMillis: Long
  ): Unit = {
    metricsCollector.recordReplicationLag(
      sourceRegion.toString,
      targetRegion.toString,
      lagMillis
    )
  }
}
```

## ã¾ã¨ã‚

### å®Ÿè£…ã—ãŸé«˜åº¦ãªæ©Ÿèƒ½

1. **åœ¨åº«äºˆæ¸¬**
   - æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆæ—¥æ¬¡å—æ‰•ã€æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã€å­£ç¯€æ€§ï¼‰
   - æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆç·šå½¢å›å¸°ã€ç§»å‹•å¹³å‡ï¼‰
   - è‡ªå‹•ç™ºæ³¨æ¨å¥¨ï¼ˆç™ºæ³¨ç‚¹ã€å®‰å…¨åœ¨åº«ã€ç·Šæ€¥åº¦åˆ¤å®šï¼‰

2. **ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œ**
   - Shared Schemaæ–¹å¼ï¼ˆè¡Œãƒ¬ãƒ™ãƒ«åˆ†é›¢ï¼‰
   - PostgreSQL Row Level Security
   - ãƒ†ãƒŠãƒ³ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†
   - ãƒ†ãƒŠãƒ³ãƒˆåˆ¥ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼ˆæ©Ÿèƒ½åˆ¶é™ã€è¨­å®šï¼‰

3. **ã‚°ãƒ­ãƒ¼ãƒãƒ«å±•é–‹**
   - ãƒãƒ«ãƒãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤
   - DynamoDB Global Tablesï¼ˆãƒãƒ«ãƒãƒã‚¹ã‚¿ãƒ¼ï¼‰
   - ãƒªãƒ¼ã‚¸ãƒ§ãƒ³åˆ¥ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
   - ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é…å»¶å¯¾ç­–

### ç™ºå±•çš„ãªè€ƒæ…®äº‹é …

1. **åœ¨åº«äºˆæ¸¬ã®é«˜åº¦åŒ–**
   - ã‚ˆã‚Šé«˜åº¦ãªæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆARIMAã€Prophetã€LSTMãªã©ï¼‰
   - å¤–éƒ¨è¦å› ã®è€ƒæ…®ï¼ˆå¤©å€™ã€ã‚¤ãƒ™ãƒ³ãƒˆã€ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
   - A/Bãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ç²¾åº¦å‘ä¸Š

2. **ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆã®æ‹¡å¼µ**
   - ãƒ†ãƒŠãƒ³ãƒˆé–“ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ï¼ˆRate Limitingï¼‰
   - ãƒ†ãƒŠãƒ³ãƒˆåˆ¥SLAä¿è¨¼
   - ãƒ†ãƒŠãƒ³ãƒˆåˆ¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒªã‚¹ãƒˆã‚¢

3. **ã‚°ãƒ­ãƒ¼ãƒãƒ«å±•é–‹ã®æœ€é©åŒ–**
   - ã‚¨ãƒƒã‚¸ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
   - åœ°ç†çš„ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æœ€é©åŒ–
   - ãƒªãƒ¼ã‚¸ãƒ§ãƒ³é–“ç«¶åˆè§£æ±ºã®é«˜åº¦åŒ–

æ¬¡ç« ã§ã¯ã€ã“ã‚Œã¾ã§å­¦ã‚“ã å†…å®¹ã‚’ã¾ã¨ã‚ã€å®Ÿè·µæ¼”ç¿’ã‚’é€šã˜ã¦ç†è§£ã‚’æ·±ã‚ã¾ã™ã€‚
