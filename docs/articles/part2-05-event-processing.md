# ç¬¬5ç« ï¼šã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ã®å®Ÿè£…

## æ¦‚è¦

æœ¬ç« ã§ã¯ã€CQRS ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ä¸­æ ¸ã‚’ãªã™**ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†**ã®å®Ÿè£…ã‚’è§£èª¬ã—ã¾ã™ã€‚ã‚³ãƒãƒ³ãƒ‰å´ã§ç”Ÿæˆã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆã‚’éåŒæœŸã«å‡¦ç†ã—ã€ã‚¯ã‚¨ãƒªå´ã®èª­ã¿å–ã‚Šãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã™ã‚‹ä»•çµ„ã¿ã‚’è©³ã—ãå­¦ã³ã¾ã™ã€‚

ä»¥ä¸‹ã®3ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’é †ã«èª¬æ˜ã—ã¾ã™ï¼š

1. **DynamoDB Streamsã®çµ±åˆ**ï¼šã‚¤ãƒ™ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã®å¤‰æ›´æ¤œçŸ¥ã¨ãƒˆãƒªã‚¬ãƒ¼
2. **Read Model Updaterã®è©³ç´°**ï¼šã‚¤ãƒ™ãƒ³ãƒˆã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
3. **çµæœæ•´åˆæ€§ã®ç®¡ç†**ï¼šéåŒæœŸå‡¦ç†ã«ãŠã‘ã‚‹ä¸€è²«æ€§ä¿è¨¼

## æŠ€è¡“çš„èƒŒæ™¯

### ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```plantuml
@startuml
!define RECTANGLE class

actor User

package "Command Side" {
  RECTANGLE CommandAPI {
    + Mutation API
  }

  RECTANGLE Aggregate {
    + Event sourcing
  }
}

database "Event Store\n(DynamoDB)" as DDB {
  collections Journal {
    [Event 1]
    [Event 2]
    [Event 3]
  }
}

package "DynamoDB Streams" {
  RECTANGLE StreamsProcessor {
    + Change detection
    + Event batching
  }
}

package "Lambda Processing" {
  RECTANGLE ReadModelUpdater {
    + Event deserialization
    + Business logic
    + Database update
  }
}

database "Read Model\n(PostgreSQL)" as PG {
  collections UserAccounts {
    [Record 1]
    [Record 2]
    [Record 3]
  }
}

package "Query Side" {
  RECTANGLE QueryAPI {
    + GraphQL API
  }
}

User --> CommandAPI : 1. Command
CommandAPI --> Aggregate : 2. Process
Aggregate --> DDB : 3. Persist event
DDB --> StreamsProcessor : 4. Trigger stream
StreamsProcessor --> ReadModelUpdater : 5. Batch events
ReadModelUpdater --> PG : 6. Update read model
User --> QueryAPI : 7. Query
QueryAPI --> PG : 8. Fetch data

note right of StreamsProcessor
  éåŒæœŸå‡¦ç†
  - çµæœæ•´åˆæ€§
  - ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒãƒ³ã‚°
  - ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥
end note

@enduml
```

### å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®è©³ç´°

```plantuml
@startuml
participant "Command Side" as CMD
database "DynamoDB\nJournal" as DDB
participant "DynamoDB\nStreams" as STREAM
participant "Lambda\nRead Model Updater" as LAMBDA
database "PostgreSQL\nRead Model" as PG
participant "Query Side" as QUERY

CMD -> DDB: Persist event
activate DDB
note right: PersistentRepr\n+ Event payload
DDB --> STREAM: Trigger change event
deactivate DDB

activate STREAM
STREAM -> STREAM: Batch events
note right: Batch size: 10\nWindow: 5 seconds
STREAM -> LAMBDA: Invoke with batch
deactivate STREAM

activate LAMBDA
LAMBDA -> LAMBDA: Deserialize PersistentRepr
LAMBDA -> LAMBDA: Extract UserAccountEvent
LAMBDA -> LAMBDA: Transform to SQL
LAMBDA -> PG: Execute INSERT/UPDATE/DELETE
activate PG
PG --> LAMBDA: Acknowledge
deactivate PG

LAMBDA --> STREAM: Return success/failure
deactivate LAMBDA

alt Success
  STREAM -> STREAM: Mark processed
else Failure
  STREAM -> STREAM: Retry (max 2 times)
  STREAM -> LAMBDA: Retry invocation
end

note over CMD,QUERY
  çµæœæ•´åˆæ€§:
  ã‚¯ã‚¨ãƒªå´ã¸ã®åæ˜ ã«ã¯
  æ•°ç§’ã®ãƒ©ã‚°ãŒç™ºç”Ÿ
end note

@enduml
```

## å®Ÿè£…ã®è©³ç´°

### 5.1 DynamoDB Streamsã®è¨­å®š

#### 5.1.1 Streamsã®æœ‰åŠ¹åŒ–

DynamoDB ãƒ†ãƒ¼ãƒ–ãƒ«ã«Streamsã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ã“ã¨ã§ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®å¤‰æ›´ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ¤œçŸ¥ã§ãã¾ã™ã€‚

**tools/dynamodb-setup/dynamodb-setup.sh** (æŠœç²‹):

```bash
# DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒ æœ‰åŠ¹åŒ–ï¼‰
aws dynamodb create-table \
  --endpoint-url $DYNAMODB_ENDPOINT \
  --table-name Journal \
  --attribute-definitions \
    AttributeName=persistence-id,AttributeType=S \
    AttributeName=sequence-nr,AttributeType=N \
  --key-schema \
    AttributeName=persistence-id,KeyType=HASH \
    AttributeName=sequence-nr,KeyType=RANGE \
  --billing-mode PAY_PER_REQUEST \
  --stream-specification \
    StreamEnabled=true \
    StreamViewType=NEW_IMAGE
```

**StreamViewType ã®ç¨®é¡**ï¼š

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | èª¬æ˜ |
|-----------|------|
| **KEYS_ONLY** | å¤‰æ›´ã•ã‚ŒãŸã‚­ãƒ¼ã®ã¿å«ã¾ã‚Œã‚‹ |
| **NEW_IMAGE** | å¤‰æ›´å¾Œã®æ–°ã—ã„ã‚¢ã‚¤ãƒ†ãƒ å…¨ä½“ï¼ˆæ¨å¥¨ï¼‰ |
| **OLD_IMAGE** | å¤‰æ›´å‰ã®å¤ã„ã‚¢ã‚¤ãƒ†ãƒ å…¨ä½“ |
| **NEW_AND_OLD_IMAGES** | å¤‰æ›´å‰å¾Œã®ä¸¡æ–¹ã®ã‚¢ã‚¤ãƒ†ãƒ  |

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ **NEW_IMAGE** ã‚’ä½¿ç”¨ã—ã€æ–°ã—ãè¿½åŠ ã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆã®ã¿ã‚’å–å¾—ã—ã¾ã™ã€‚

---

#### 5.1.2 Event Source Mapping ã®ä½œæˆ

Lambdaé–¢æ•°ã‚’DynamoDB Streamsã«æ¥ç¶šã™ã‚‹ãŸã‚ã€**Event Source Mapping**ã‚’ä½œæˆã—ã¾ã™ã€‚

**scripts/deploy-lambda-localstack.sh** (æŠœç²‹):

```bash
# DynamoDB ã‚¹ãƒˆãƒªãƒ¼ãƒ  ARN ã‚’å–å¾—
STREAM_ARN=$(aws dynamodb describe-table \
    --endpoint-url $ENDPOINT_URL \
    --table-name $TABLE_NAME \
    --query 'Table.LatestStreamArn' \
    --output text)

# ã‚¤ãƒ™ãƒ³ãƒˆã‚½ãƒ¼ã‚¹ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
aws lambda create-event-source-mapping \
    --endpoint-url $ENDPOINT_URL \
    --function-name $FUNCTION_NAME \
    --event-source-arn $STREAM_ARN \
    --starting-position LATEST \
    --batch-size 10 \
    --maximum-batching-window-in-seconds 5
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¬æ˜**ï¼š

- **event-source-arn**: DynamoDB Streamsã®ARN
- **starting-position**:
  - `LATEST`: æœ€æ–°ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‹ã‚‰å‡¦ç†é–‹å§‹ï¼ˆæ¨å¥¨ï¼‰
  - `TRIM_HORIZON`: ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®å…ˆé ­ã‹ã‚‰å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‡¦ç†
- **batch-size**: ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ï¼ˆ1ã€œ10000ï¼‰
- **maximum-batching-window-in-seconds**: ãƒãƒƒãƒãƒ³ã‚°å¾…æ©Ÿæ™‚é–“ï¼ˆ0ã€œ300ç§’ï¼‰

**ãƒãƒƒãƒãƒ³ã‚°ã®ä»•çµ„ã¿**ï¼š

```
ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿ:
e1 (0ç§’) â†’ e2 (1ç§’) â†’ e3 (2ç§’) â†’ e4 (3ç§’) â†’ e5 (4ç§’)

ãƒãƒƒãƒãƒ³ã‚°çµæœï¼ˆbatch-size=10, window=5ç§’ã®å ´åˆï¼‰:
Batch 1: [e1, e2, e3, e4, e5] (5ç§’çµŒéã¾ãŸã¯ã‚µã‚¤ã‚ºä¸Šé™ã§ãƒˆãƒªã‚¬ãƒ¼)

åŠ¹ç‡åŒ–:
- Lambdaèµ·å‹•å›æ•°ã‚’å‰Šæ¸›
- ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå‘ä¸Š
- ã‚³ã‚¹ãƒˆå‰Šæ¸›
```

---

### 5.2 Read Model Updater ã®è©³ç´°å®Ÿè£…

#### 5.2.1 Lambda Handler ã®æ§‹é€ 

ç¬¬4ç« ã§åŸºæœ¬çš„ãªå®Ÿè£…ã‚’è§£èª¬ã—ã¾ã—ãŸãŒã€ã“ã“ã§ã¯ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥ã«ç„¦ç‚¹ã‚’å½“ã¦ã¾ã™ã€‚

**apps/read-model-updater/src/main/scala/io/github/j5ik2o/pcqrses/readModelUpdater/LambdaHandler.scala** (è©³ç´°ç‰ˆ):

```scala
class LambdaHandler extends RequestHandler[DynamodbEvent, LambdaResponse] {

  private val logger = LoggerFactory.getLogger(getClass)

  override def handleRequest(input: DynamodbEvent, context: Context): LambdaResponse = {
    try {
      logger.info(s"Received DynamoDB event with ${input.getRecords.size} records")

      // ä¸¦è¡Œå‡¦ç†ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
      val results = input.getRecords.asScala.toList.par.map(processRecord).toList

      val failures = results.collect { case Left(error) => error }
      val successes = results.collect { case Right(_) => () }

      // éƒ¨åˆ†çš„ãªå¤±æ•—ã§ã‚‚ç¶™ç¶šï¼ˆ207 Multi-Statusï¼‰
      if (failures.nonEmpty) {
        logger.error(s"Failed to process ${failures.size} out of ${results.size} records")
        failures.foreach { error =>
          logger.error(s"Processing error: ${error.message}", error.exception.orNull)
        }
        LambdaResponse(
          statusCode = 207, // Multi-Status
          body = objectMapper.writeValueAsString(
            ResponseBody(
              message = s"Processed ${successes.size} records successfully, ${failures.size} failed",
              error = Some(failures.map(_.message).mkString("; "))
            )
          )
        )
      } else {
        logger.info(s"Successfully processed ${successes.size} records")
        LambdaResponse(
          statusCode = 200,
          body = objectMapper.writeValueAsString(
            ResponseBody(message = s"Successfully processed ${successes.size} records")
          )
        )
      }
    } catch {
      case ex: Exception =>
        logger.error("Unexpected error processing DynamoDB event", ex)
        LambdaResponse(
          statusCode = 500,
          body = objectMapper.writeValueAsString(
            ResponseBody(message = "Internal server error", error = Some(ex.getMessage))
          )
        )
    }
  }
}
```

**ä¸¦è¡Œå‡¦ç†ã«ã‚ˆã‚‹æœ€é©åŒ–**ï¼š

- **`.par.map()`**: Scala ã®Parallel Collectionsã§ä¸¦è¡Œå‡¦ç†
- **ãƒ¡ãƒªãƒƒãƒˆ**: è¤‡æ•°ã‚¤ãƒ™ãƒ³ãƒˆã‚’åŒæ™‚å‡¦ç†ã—ã¦ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå‘ä¸Š
- **æ³¨æ„ç‚¹**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ã®ã‚µã‚¤ã‚ºã‚’é©åˆ‡ã«è¨­å®š

---

#### 5.2.2 ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

ã™ã¹ã¦ã®DynamoDBãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‡¦ç†ã™ã‚‹ã®ã§ã¯ãªãã€ç‰¹å®šã®ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ã¿ã‚’å‡¦ç†ã—ã¾ã™ã€‚

```scala
private def processRecord(record: DynamodbStreamRecord): Either[ProcessingError, Unit] = {
  try {
    // 1. ãƒ†ãƒ¼ãƒ–ãƒ«åã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    val tableName = record.getEventSourceARN.split("/")(1)
    if (tableName != "Journal") {
      logger.debug(s"Skipping record from table: $tableName")
      return Right(())
    }

    // 2. NewImageã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼ˆDELETE ã‚¤ãƒ™ãƒ³ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    val newImage = Option(record.getDynamodb.getNewImage)
    if (newImage.isEmpty) {
      logger.debug("Skipping record without NewImage (likely DELETE event)")
      return Right(())
    }

    val attributes = newImage.get.asScala

    // 3. persistence-id ã§ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚¿ã‚¤ãƒ—ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    val persistenceIdOpt = Option(attributes.get("persistence-id"))
      .flatMap(attrOpt => Option(attrOpt.map(_.getS).orNull))

    if (persistenceIdOpt.isEmpty || !persistenceIdOpt.get.startsWith(UserAccountEntityTypePrefix)) {
      logger.debug(s"Skipping record with persistence-id: ${persistenceIdOpt.getOrElse("null")}")
      return Right(())
    }

    // 4. ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ã¸é€²ã‚€
    val messageBytes = extractMessageBytes(attributes)
    deserializePersistentReprAndProcess(messageBytes)

  } catch {
    case ex: Exception =>
      logger.error("Error processing record", ex)
      Left(ProcessingError(s"Error processing record: ${ex.getMessage}", Some(ex)))
  }
}
```

**ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®åˆ©ç‚¹**ï¼š

- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š**: ä¸è¦ãªãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ—©æœŸã«ã‚¹ã‚­ãƒƒãƒ—
- **ã‚³ã‚¹ãƒˆå‰Šæ¸›**: Lambdaå®Ÿè¡Œæ™‚é–“ã‚’çŸ­ç¸®
- **æ˜ç¢ºãªè²¬å‹™**: ç‰¹å®šã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ã¿å‡¦ç†

---

#### 5.2.3 ã¹ãç­‰æ€§ã®å®Ÿè£…

åŒã˜ã‚¤ãƒ™ãƒ³ãƒˆãŒè¤‡æ•°å›é…ä¿¡ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ã¹ãç­‰æ€§ã‚’ä¿è¨¼ã—ã¾ã™ã€‚

**æˆ¦ç•¥1: insertOrUpdate ã‚’ä½¿ç”¨**

```scala
case UserAccountEvent.Created_V1(_, entityId, name, _, occurredAt) =>
  val record = component.UserAccountsRecord(
    id = entityId.asString,
    firstName = name.breachEncapsulationOfFirstName.asString,
    lastName = name.breachEncapsulationOfLastName.asString,
    createdAt = Timestamp.from(occurredAt.asInstant()),
    updatedAt = Timestamp.from(occurredAt.asInstant())
  )
  // insertOrUpdate ã«ã‚ˆã‚Šã€ã™ã§ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯æ›´æ–°
  component.UserAccountsDao.insertOrUpdate(record)
```

**æˆ¦ç•¥2: ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«**

```sql
-- ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE event_processed_log (
    persistence_id VARCHAR NOT NULL,
    sequence_nr BIGINT NOT NULL,
    processed_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (persistence_id, sequence_nr)
);

CREATE INDEX idx_event_processed_log_processed_at ON event_processed_log(processed_at);
```

```scala
private def processEventIdempotently(
  persistenceId: String,
  sequenceNr: Long,
  event: UserAccountEvent
): Either[ProcessingError, Unit] = {
  import databaseConfig.profile.api.*

  // ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å†…ã§å®Ÿè¡Œ
  val action = for {
    // 1. ã™ã§ã«å‡¦ç†æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
    alreadyProcessed <- sql"""
      SELECT COUNT(*) FROM event_processed_log
      WHERE persistence_id = $persistenceId AND sequence_nr = $sequenceNr
    """.as[Int].map(_.head > 0)

    _ <- if (alreadyProcessed) {
      logger.info(s"Event already processed: $persistenceId/$sequenceNr")
      DBIO.successful(())
    } else {
      for {
        // 2. ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†
        _ <- processUserAccountEventAction(event)

        // 3. å‡¦ç†ãƒ­ã‚°ã«è¨˜éŒ²
        _ <- sqlu"""
          INSERT INTO event_processed_log (persistence_id, sequence_nr)
          VALUES ($persistenceId, $sequenceNr)
        """
      } yield ()
    }
  } yield ()

  try {
    Await.result(db.run(action.transactionally), databaseOperationTimeout)
    Right(())
  } catch {
    case ex: Exception =>
      Left(ProcessingError(s"Error processing event: ${ex.getMessage}", Some(ex)))
  }
}
```

**ãƒ¡ãƒªãƒƒãƒˆ**ï¼š

- **å®Œå…¨ãªã¹ãç­‰æ€§**: åŒã˜ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¤‡æ•°å›å—ã‘å–ã£ã¦ã‚‚å®‰å…¨
- **ç›£æŸ»è¨¼è·¡**: ã©ã®ã‚¤ãƒ™ãƒ³ãƒˆãŒã„ã¤å‡¦ç†ã•ã‚ŒãŸã‹ã‚’è¨˜éŒ²
- **ãƒ‡ãƒãƒƒã‚°æ”¯æ´**: å‡¦ç†æ¸ˆã¿ã‚¤ãƒ™ãƒ³ãƒˆã®å±¥æ­´ã‚’ç¢ºèªå¯èƒ½

---

### 5.3 çµæœæ•´åˆæ€§ã®ç®¡ç†

#### 5.3.1 éåŒæœŸå‡¦ç†ã®èª²é¡Œ

CQRS ã§ã¯ã€ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã¨ã‚¯ã‚¨ãƒªå´ã¸ã®åæ˜ ã®é–“ã«ã‚¿ã‚¤ãƒ ãƒ©ã‚°ãŒç™ºç”Ÿã—ã¾ã™ã€‚

```plantuml
@startuml
actor User

User -> CommandAPI: 1. createUserAccount
activate CommandAPI
CommandAPI -> Aggregate: 2. Process command
Aggregate -> DynamoDB: 3. Persist event (0ms)
DynamoDB --> CommandAPI: 4. Success
CommandAPI --> User: 5. Return UserAccountId (50ms)
deactivate CommandAPI

...Asynchronous processing...

DynamoDB -> Lambda: 6. Stream event (100ms)
activate Lambda
Lambda -> PostgreSQL: 7. Update read model (150ms)
deactivate Lambda

User -> QueryAPI: 8. getUserAccount (75ms)
activate QueryAPI
QueryAPI -> PostgreSQL: 9. Query
PostgreSQL --> QueryAPI: 10. Not found yet!
QueryAPI --> User: 11. Empty result
deactivate QueryAPI

note over User
  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä½œæˆã—ãŸã¯ãšã®
  ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒã¾ã è¦‹ãˆãªã„!
end note

User -> QueryAPI: 12. Retry query (200ms)
activate QueryAPI
QueryAPI -> PostgreSQL: 13. Query
PostgreSQL --> QueryAPI: 14. Found!
QueryAPI --> User: 15. UserAccount
deactivate QueryAPI

@enduml
```

---

#### 5.3.2 çµæœæ•´åˆæ€§ã¸ã®å¯¾å¿œç­–

**æˆ¦ç•¥1: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ãƒªãƒˆãƒ©ã‚¤**

```typescript
// ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ã®ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆTypeScriptä¾‹ï¼‰
async function createUserAccountWithRetry(input: CreateUserAccountInput): Promise<UserAccount> {
  // 1. ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
  const result = await graphqlClient.mutate({
    mutation: CREATE_USER_ACCOUNT,
    variables: { input }
  });

  const userAccountId = result.data.createUserAccount.id;

  // 2. ã‚¯ã‚¨ãƒªå´ã¸ã®åæ˜ ã‚’å¾…ã¤ï¼ˆExponential Backoffï¼‰
  let retries = 0;
  const maxRetries = 5;
  const baseDelay = 100; // ms

  while (retries < maxRetries) {
    try {
      const account = await graphqlClient.query({
        query: GET_USER_ACCOUNT,
        variables: { userAccountId },
        fetchPolicy: 'network-only' // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–
      });

      if (account.data.getUserAccount) {
        return account.data.getUserAccount;
      }
    } catch (error) {
      // Not found - ãƒªãƒˆãƒ©ã‚¤
    }

    // Exponential backoff: 100ms, 200ms, 400ms, 800ms, 1600ms
    const delay = baseDelay * Math.pow(2, retries);
    await new Promise(resolve => setTimeout(resolve, delay));
    retries++;
  }

  throw new Error('User account creation succeeded, but read model update timed out');
}
```

**æˆ¦ç•¥2: UI ã§ã®æ¥½è¦³çš„æ›´æ–°**

```typescript
// æ¥½è¦³çš„æ›´æ–°: UIã«å³åº§ã«åæ˜ 
const optimisticResponse = {
  createUserAccount: {
    __typename: 'CreateUserAccountResult',
    id: temporaryId, // ä»®ã®ID
  }
};

await graphqlClient.mutate({
  mutation: CREATE_USER_ACCOUNT,
  variables: { input },
  optimisticResponse, // UIã«å³åº§ã«åæ˜ 
  update: (cache, { data }) => {
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
    cache.writeQuery({
      query: GET_USER_ACCOUNTS,
      data: {
        getUserAccounts: [...existingAccounts, data.createUserAccount]
      }
    });
  }
});
```

**æˆ¦ç•¥3: ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•UIï¼ˆWebSocket/SSEï¼‰**

```scala
// WebSocketã§ã‚¯ã‚¨ãƒªå´ã®æ›´æ–°ã‚’é€šçŸ¥
case class ReadModelUpdatedEvent(
  entityType: String,
  entityId: String,
  operation: String // "created", "updated", "deleted"
)

// Lambda ã‹ã‚‰ Pub/Sub ã«ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºè¡Œ
private def notifyReadModelUpdate(event: UserAccountEvent): Unit = {
  val notification = ReadModelUpdatedEvent(
    entityType = "UserAccount",
    entityId = event.entityId.asString,
    operation = event match {
      case _: UserAccountEvent.Created_V1 => "created"
      case _: UserAccountEvent.Renamed_V1 => "updated"
      case _: UserAccountEvent.Deleted_V1 => "deleted"
    }
  )

  // Pub/Sub (ä¾‹: Redis Pub/Sub, AWS SNS, etc.)
  pubSubClient.publish("read-model-updates", notification)
}

// ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§WebSocketæ¥ç¶š
const ws = new WebSocket('ws://query-api/updates');
ws.onmessage = (event) => {
  const update = JSON.parse(event.data);
  if (update.entityType === 'UserAccount' && update.operation === 'created') {
    // UIã‚’æ›´æ–°
    refetchUserAccounts();
  }
};
```

---

#### 5.3.3 ã‚¤ãƒ™ãƒ³ãƒˆé †åºã®ä¿è¨¼

DynamoDB Streams ã¯ã€**ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚­ãƒ¼å˜ä½**ã§ã‚¤ãƒ™ãƒ³ãƒˆã®é †åºã‚’ä¿è¨¼ã—ã¾ã™ã€‚

```
persistence-id: "UserAccount-01KABC..."
  â†’ Event 1 (sequence-nr: 1)
  â†’ Event 2 (sequence-nr: 2)  // Event 1 ã®å¾Œã«å¿…ãšå‡¦ç†ã•ã‚Œã‚‹
  â†’ Event 3 (sequence-nr: 3)  // Event 2 ã®å¾Œã«å¿…ãšå‡¦ç†ã•ã‚Œã‚‹
```

**é †åºä¿è¨¼ã®ä»•çµ„ã¿**ï¼š

1. DynamoDB Streams ã¯ã‚·ãƒ£ãƒ¼ãƒ‰ï¼ˆãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ï¼‰å˜ä½ã§ã‚¤ãƒ™ãƒ³ãƒˆã‚’é…ä¿¡
2. åŒã˜persistence-idã®ã‚¤ãƒ™ãƒ³ãƒˆã¯åŒã˜ã‚·ãƒ£ãƒ¼ãƒ‰ã«é…ç½®
3. Lambda ã¯å„ã‚·ãƒ£ãƒ¼ãƒ‰ã‚’é †æ¬¡å‡¦ç†

**é †åºé•åã®æ¤œå‡º**ï¼š

```scala
private def validateEventOrder(
  persistenceId: String,
  sequenceNr: Long
): Either[ProcessingError, Unit] = {
  import databaseConfig.profile.api.*

  // æœ€å¾Œã«å‡¦ç†ã—ãŸã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ã‚’å–å¾—
  val lastProcessedSeqNr = Await.result(
    db.run(sql"""
      SELECT MAX(sequence_nr) FROM event_processed_log
      WHERE persistence_id = $persistenceId
    """.as[Option[Long]].map(_.flatten.getOrElse(0L))),
    Duration.Inf
  )

  if (sequenceNr != lastProcessedSeqNr + 1) {
    // é †åºé•åã‚’æ¤œå‡º
    Left(ProcessingError(
      s"Event order violation: expected seq ${lastProcessedSeqNr + 1}, got $sequenceNr",
      None
    ))
  } else {
    Right(())
  }
}
```

---

#### 5.3.4 ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¢ƒç•Œã®è¨­è¨ˆ

Read Model Updater ã§ã¯ã€ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ã¨ãƒ­ã‚°è¨˜éŒ²ã‚’1ã¤ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã«ã¾ã¨ã‚ã¾ã™ã€‚

```scala
private def processUserAccountEventTransactionally(
  persistenceId: String,
  sequenceNr: Long,
  event: UserAccountEvent
): Either[ProcessingError, Unit] = {
  import databaseConfig.profile.api.*

  val transaction = for {
    // 1. ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ï¼ˆINSERT/UPDATE/DELETEï¼‰
    _ <- processUserAccountEventAction(event)

    // 2. å‡¦ç†ãƒ­ã‚°è¨˜éŒ²
    _ <- sqlu"""
      INSERT INTO event_processed_log (persistence_id, sequence_nr)
      VALUES ($persistenceId, $sequenceNr)
    """
  } yield ()

  try {
    // ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    Await.result(
      db.run(transaction.transactionally),
      databaseOperationTimeout
    )
    Right(())
  } catch {
    case ex: PSQLException if ex.getSQLState == "23505" =>
      // Unique constraint violation - ã™ã§ã«å‡¦ç†æ¸ˆã¿
      logger.info(s"Event already processed (duplicate): $persistenceId/$sequenceNr")
      Right(())
    case ex: Exception =>
      // ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ - ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡
      logger.error(s"Transaction failed: ${ex.getMessage}", ex)
      Left(ProcessingError(s"Transaction error: ${ex.getMessage}", Some(ex)))
  }
}
```

**ACID ç‰¹æ€§ã®æ´»ç”¨**ï¼š

- **Atomicity**: ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ã¨ãƒ­ã‚°è¨˜éŒ²ãŒä¸¡æ–¹æˆåŠŸã™ã‚‹ã‹ä¸¡æ–¹å¤±æ•—
- **Consistency**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¶ç´„ã«ã‚ˆã‚Šä¸€è²«æ€§ã‚’ä¿è¨¼
- **Isolation**: ä¸¦è¡Œå®Ÿè¡Œã—ã¦ã‚‚ç«¶åˆã—ãªã„
- **Durability**: ã‚³ãƒŸãƒƒãƒˆå¾Œã¯æ°¸ç¶šåŒ–ã‚’ä¿è¨¼

---

### 5.4 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒªãƒˆãƒ©ã‚¤

#### 5.4.1 ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥

Lambda ã®Event Source Mapping ã¯ã€è‡ªå‹•çš„ã«ãƒªãƒˆãƒ©ã‚¤ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

**è¨­å®šä¾‹**ï¼š

```bash
aws lambda create-event-source-mapping \
    --function-name read-model-updater \
    --event-source-arn $STREAM_ARN \
    --starting-position LATEST \
    --maximum-retry-attempts 2 \
    --maximum-record-age-in-seconds 3600 \
    --on-failure-destination-config "OnFailure={Destination=arn:aws:sqs:...}"
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¬æ˜**ï¼š

- **maximum-retry-attempts**: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2ï¼‰
- **maximum-record-age-in-seconds**: ãƒ¬ã‚³ãƒ¼ãƒ‰ã®æœ€å¤§ä¿æŒæ™‚é–“ï¼ˆ1æ™‚é–“ï¼‰
- **on-failure-destination-config**: å¤±æ•—æ™‚ã®é€ä¿¡å…ˆï¼ˆSQSã€SNSï¼‰

**ãƒªãƒˆãƒ©ã‚¤ã®ä»•çµ„ã¿**ï¼š

```
Attempt 1: Lambdaå®Ÿè¡Œ â†’ å¤±æ•—
  â†“ (Exponential backoff: 1ç§’)
Attempt 2: Lambdaå®Ÿè¡Œ â†’ å¤±æ•—
  â†“ (Exponential backoff: 2ç§’)
Attempt 3: Lambdaå®Ÿè¡Œ â†’ å¤±æ•—
  â†“
DLQ (Dead Letter Queue) ã«é€ä¿¡
```

---

#### 5.4.2 ã‚¨ãƒ©ãƒ¼åˆ†é¡ã¨ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

ã‚¨ãƒ©ãƒ¼ã‚’**ä¸€æ™‚çš„ã‚¨ãƒ©ãƒ¼**ã¨**æ°¸ç¶šçš„ã‚¨ãƒ©ãƒ¼**ã«åˆ†é¡ã—ã¾ã™ã€‚

```scala
sealed trait ProcessingErrorType
object ProcessingErrorType {
  case object Transient extends ProcessingErrorType  // ãƒªãƒˆãƒ©ã‚¤å¯èƒ½
  case object Permanent extends ProcessingErrorType  // ãƒªãƒˆãƒ©ã‚¤ä¸å¯
}

case class ProcessingError(
  message: String,
  exception: Option[Throwable],
  errorType: ProcessingErrorType = ProcessingErrorType.Transient
)

private def classifyError(ex: Throwable): ProcessingErrorType = ex match {
  // ä¸€æ™‚çš„ã‚¨ãƒ©ãƒ¼ï¼ˆãƒªãƒˆãƒ©ã‚¤å¯èƒ½ï¼‰
  case _: SQLException if ex.getMessage.contains("connection") =>
    ProcessingErrorType.Transient
  case _: java.net.SocketTimeoutException =>
    ProcessingErrorType.Transient
  case _: org.postgresql.util.PSQLException if ex.getMessage.contains("deadlock") =>
    ProcessingErrorType.Transient

  // æ°¸ç¶šçš„ã‚¨ãƒ©ãƒ¼ï¼ˆãƒªãƒˆãƒ©ã‚¤ä¸å¯ï¼‰
  case _: IllegalArgumentException =>
    ProcessingErrorType.Permanent
  case _: com.google.protobuf.InvalidProtocolBufferException =>
    ProcessingErrorType.Permanent
  case _: org.postgresql.util.PSQLException if ex.getMessage.contains("constraint") =>
    ProcessingErrorType.Permanent

  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä¸€æ™‚çš„ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦æ‰±ã†
  case _ =>
    ProcessingErrorType.Transient
}
```

---

#### 5.4.3 Dead Letter Queue (DLQ) ã®æ´»ç”¨

ãƒªãƒˆãƒ©ã‚¤ã«å¤±æ•—ã—ãŸã‚¤ãƒ™ãƒ³ãƒˆã‚’DLQã«é€ä¿¡ã—ã€å¾Œã§èª¿æŸ»ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```bash
# DLQç”¨ã®SQSã‚­ãƒ¥ãƒ¼ã‚’ä½œæˆ
aws sqs create-queue \
  --queue-name read-model-updater-dlq \
  --endpoint-url http://localstack:4566

# Event Source Mapping ã«DLQã‚’è¨­å®š
aws lambda create-event-source-mapping \
  --function-name read-model-updater \
  --event-source-arn $STREAM_ARN \
  --on-failure-destination-config "OnFailure={Destination=arn:aws:sqs:ap-northeast-1:000000000000:read-model-updater-dlq}"
```

**DLQ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†**ï¼š

```scala
// DLQã‹ã‚‰å¤±æ•—ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—ã—ã¦å†å‡¦ç†ã™ã‚‹ãƒãƒƒãƒã‚¸ãƒ§ãƒ–
object DLQProcessor {
  def processFailedEvents(): Unit = {
    val sqsClient = AmazonSQSClientBuilder.defaultClient()
    val queueUrl = "https://sqs.ap-northeast-1.amazonaws.com/.../read-model-updater-dlq"

    while (true) {
      val messages = sqsClient.receiveMessage(queueUrl).getMessages.asScala

      messages.foreach { message =>
        try {
          // ã‚¤ãƒ™ãƒ³ãƒˆã‚’å†å‡¦ç†
          val dynamodbEvent = parseMessage(message.getBody)
          val handler = new LambdaHandler()
          handler.handleRequest(dynamodbEvent, null)

          // æˆåŠŸã—ãŸã‚‰DLQã‹ã‚‰å‰Šé™¤
          sqsClient.deleteMessage(queueUrl, message.getReceiptHandle)
        } catch {
          case ex: Exception =>
            // å†å‡¦ç†ã‚‚å¤±æ•— - ã‚¢ãƒ©ãƒ¼ãƒˆã‚’é€ä¿¡
            logger.error(s"Failed to reprocess DLQ message: ${ex.getMessage}", ex)
        }
      }

      Thread.sleep(60000) // 1åˆ†ã”ã¨ã«ãƒãƒ¼ãƒªãƒ³ã‚°
    }
  }
}
```

---

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®æœ€é©åŒ–

**æ¨å¥¨è¨­å®š**ï¼š

- **ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼é‡è¦–**: batch-size=1, window=0ç§’
- **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆé‡è¦–**: batch-size=10, window=5ç§’
- **ã‚³ã‚¹ãƒˆé‡è¦–**: batch-size=100, window=10ç§’

```bash
# ç’°å¢ƒã«å¿œã˜ã¦èª¿æ•´
aws lambda update-event-source-mapping \
  --uuid $MAPPING_UUID \
  --batch-size 10 \
  --maximum-batching-window-in-seconds 5
```

---

### 2. Lambda ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š

```bash
aws lambda update-function-configuration \
  --function-name read-model-updater \
  --timeout 300 \  # 5åˆ†ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ç§’ï¼‰
  --memory-size 512  # ãƒ¡ãƒ¢ãƒªã‚’å¢—ã‚„ã™ã¨CPUã‚‚å¢—ãˆã‚‹
```

**ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®ç›®å®‰**ï¼š

- batch-size=1: 30ç§’
- batch-size=10: 60ç§’
- batch-size=100: 300ç§’

---

### 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ã®è¨­å®š

```hocon
read-model-updater.slick.db {
  connectionPool = "HikariCP"
  maxConnections = 10      # LambdaåŒæ™‚å®Ÿè¡Œæ•°ã«å¿œã˜ã¦èª¿æ•´
  minConnections = 5
  connectionTimeout = 30000
  idleTimeout = 600000     # 10åˆ†
  maxLifetime = 1800000    # 30åˆ†
}
```

**ä¸¦è¡Œå®Ÿè¡Œæ™‚ã®æ³¨æ„**ï¼š

- Lambda ã®åŒæ™‚å®Ÿè¡Œæ•° Ã— maxConnections â‰¤ PostgreSQL ã® max_connections
- ä¾‹: Lambda 10ä¸¦è¡Œ Ã— 10æ¥ç¶š = 100æ¥ç¶š

---

### 4. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

**é‡è¦ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹**ï¼š

1. **Lambda Duration**: å®Ÿè¡Œæ™‚é–“ã®ç›£è¦–
2. **Lambda Errors**: ã‚¨ãƒ©ãƒ¼ç‡ã®ç›£è¦–
3. **Lambda Throttles**: ã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚°ã®æ¤œå‡º
4. **DynamoDB Streams Iterator Age**: å‡¦ç†é…å»¶ã®ç›£è¦–
5. **DLQ Message Count**: å¤±æ•—ã‚¤ãƒ™ãƒ³ãƒˆæ•°ã®ç›£è¦–

**CloudWatch Logs Insights ã‚¯ã‚¨ãƒªä¾‹**ï¼š

```sql
-- ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®é›†è¨ˆ
fields @timestamp, @message
| filter @message like /ERROR/
| stats count() by bin(5m)

-- å‡¦ç†æ™‚é–“ã®åˆ†æ
fields @timestamp, @duration
| stats avg(@duration), max(@duration), p99(@duration) by bin(5m)
```

---

### 5. ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆ

```bash
# LocalStackç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆ
./scripts/deploy-lambda-localstack.sh

# DynamoDBã«ã‚¤ãƒ™ãƒ³ãƒˆã‚’æŒ¿å…¥ã—ã¦Lambdaã‚’ãƒˆãƒªã‚¬ãƒ¼
aws dynamodb put-item \
  --endpoint-url http://localhost:50503 \
  --table-name Journal \
  --item '{"persistence-id":{"S":"UserAccount-test"},"sequence-nr":{"N":"1"},"message":{"B":"..."}}'

# Lambdaå®Ÿè¡Œãƒ­ã‚°ã‚’ç¢ºèª
docker logs -f $(docker ps -q -f name=localstack)
```

---

## ã¾ã¨ã‚

æœ¬ç« ã§ã¯ã€ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ã®å®Ÿè£…ã‚’ä»¥ä¸‹ã®é †ã§è§£èª¬ã—ã¾ã—ãŸï¼š

1. **DynamoDB Streamsã®çµ±åˆ**: Event Source Mappingã«ã‚ˆã‚‹è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼
2. **Read Model Updaterã®è©³ç´°**: ã¹ãç­‰æ€§ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³
3. **çµæœæ•´åˆæ€§ã®ç®¡ç†**: éåŒæœŸå‡¦ç†ã®èª²é¡Œã¨å¯¾å¿œç­–
4. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥ã¨DLQ

ã“ã‚Œã‚‰ã®å®Ÿè£…ã«ã‚ˆã‚Šã€ä»¥ä¸‹ãŒå®Ÿç¾ã•ã‚Œã¾ã™ï¼š

- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: DynamoDB Streamsã¨Lambdaã«ã‚ˆã‚‹è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
- **ä¿¡é ¼æ€§**: ãƒªãƒˆãƒ©ã‚¤ã¨DLQã«ã‚ˆã‚‹å¤±æ•—ã‚¤ãƒ™ãƒ³ãƒˆã®ç®¡ç†
- **ä¸€è²«æ€§**: ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã¨ã¹ãç­‰æ€§ã«ã‚ˆã‚‹çµæœæ•´åˆæ€§ã®ä¿è¨¼
- **ç›£è¦–æ€§**: CloudWatch Logsã«ã‚ˆã‚‹è©³ç´°ãªãƒ­ã‚°è¨˜éŒ²

æ¬¡ç« ã§ã¯ã€**è¨­å®šç®¡ç†ã¨ãƒ‡ãƒ—ãƒ­ã‚¤**ã‚’è§£èª¬ã—ã¾ã™ã€‚

---

ğŸ‘‰ [ç¬¬6ç« ï¼šè¨­å®šç®¡ç†ã¨ãƒ‡ãƒ—ãƒ­ã‚¤](part2-06-configuration.md)
