# 作業履歴 2025-11-18

## 概要

2025-11-18の作業内容をまとめています。

## コミット: 865f4e0

### メッセージ

```
refactor: Organize imports and simplify Scala collection conversions in LambdaHandler.scala
```

### 変更されたファイル

- M	apps/read-model-updater/src/main/scala/io/github/j5ik2o/pcqrses/readModelUpdater/LambdaHandler.scala

### 変更内容

```diff
commit 865f4e03d9591ab0dcc29d24652c5664b6ceefec
Author: Junichi Kato <j5ik2o@gmail.com>
Date:   Tue Nov 18 22:15:48 2025 +0900

    refactor: Organize imports and simplify Scala collection conversions in LambdaHandler.scala

diff --git a/apps/read-model-updater/src/main/scala/io/github/j5ik2o/pcqrses/readModelUpdater/LambdaHandler.scala b/apps/read-model-updater/src/main/scala/io/github/j5ik2o/pcqrses/readModelUpdater/LambdaHandler.scala
index 7836207..fbdf3d2 100644
--- a/apps/read-model-updater/src/main/scala/io/github/j5ik2o/pcqrses/readModelUpdater/LambdaHandler.scala
+++ b/apps/read-model-updater/src/main/scala/io/github/j5ik2o/pcqrses/readModelUpdater/LambdaHandler.scala
@@ -1,8 +1,8 @@
 package io.github.j5ik2o.pcqrses.readModelUpdater
 
-import com.amazonaws.services.lambda.runtime.{Context, RequestHandler}
 import com.amazonaws.services.lambda.runtime.events.DynamodbEvent
 import com.amazonaws.services.lambda.runtime.events.DynamodbEvent.DynamodbStreamRecord
+import com.amazonaws.services.lambda.runtime.{Context, RequestHandler}
 import com.fasterxml.jackson.databind.ObjectMapper
 import com.fasterxml.jackson.module.scala.DefaultScalaModule
 import com.typesafe.config.ConfigFactory
@@ -17,8 +17,9 @@ import slick.jdbc.JdbcProfile
 
 import java.nio.ByteBuffer
 import java.sql.Timestamp
-import scala.concurrent.duration.Duration
 import scala.concurrent.Await
+import scala.concurrent.duration.Duration
+import scala.jdk.CollectionConverters.*
 import scala.util.Try
 
 class LambdaHandler extends RequestHandler[DynamodbEvent, LambdaResponse] {
@@ -192,7 +193,7 @@ class LambdaHandler extends RequestHandler[DynamodbEvent, LambdaResponse] {
       val component = new UserAccountsComponent {
         override val profile: JdbcProfile = databaseConfig.profile
       }
-      import databaseConfig.profile.api._
+      import databaseConfig.profile.api.*
 
       val action = event match {
         case UserAccountEvent.Created_V1(_, entityId, name, _, occurredAt) =>
@@ -231,17 +232,4 @@ class LambdaHandler extends RequestHandler[DynamodbEvent, LambdaResponse] {
 
   private case class ProcessingError(message: String, exception: Option[Throwable])
 
-  private implicit class ScalaMapConverter[A, B](map: java.util.Map[A, B]) {
-    def asScala: scala.collection.mutable.Map[A, B] = {
-      import scala.jdk.CollectionConverters._
-      map.asScala
-    }
-  }
-
-  private implicit class JavaListConverter[A](list: java.util.List[A]) {
-    def asScala: scala.collection.mutable.Buffer[A] = {
-      import scala.jdk.CollectionConverters._
-      list.asScala
-    }
-  }
 }

```

## コミット: ad11b26

### メッセージ

```
docs: Add guidelines for Japanese language usage in AGENTS.md
```

### 変更されたファイル

- A	.codex/AGENTS.md

### 変更内容

```diff
commit ad11b260692d64fa6311b4987334d9a87cd38ab9
Author: Junichi Kato <j5ik2o@gmail.com>
Date:   Tue Nov 18 15:56:03 2025 +0900

    docs: Add guidelines for Japanese language usage in AGENTS.md

diff --git a/.codex/AGENTS.md b/.codex/AGENTS.md
new file mode 100644
index 0000000..3488988
--- /dev/null
+++ b/.codex/AGENTS.md
@@ -0,0 +1,3 @@
+- すべて日本語でやりとりすること
+- ソースコード以外の生成されるファイルも日本語で記述すること
+- ソースコードの編集はPythonを使わないでapply_patchを使ってください

```

## コミット: 74ffa64

### メッセージ

```
Update README.md
```

### 変更されたファイル

- M	README.md

### 変更内容

```diff
commit 74ffa64be1cb98d007009cfd4202ff2217472bb8
Author: Junichi Kato <j5ik2o@gmail.com>
Date:   Tue Nov 18 17:45:28 2025 +0900

    Update README.md

diff --git a/README.md b/README.md
index 3d3788a..a390ab2 100644
--- a/README.md
+++ b/README.md
@@ -14,13 +14,13 @@ Apache Pekkoを使用したCQRS（Command Query Responsibility Segregation）と
 
 ```mermaid
 graph TB
-    subgraph "Command Side (Write Model)"
+    subgraph "Command Side"
         CommandAPI["Command API<br/>(GraphQL)<br/>Port: 50501"]
         PekkoActors["Pekko Actors<br/>(Event Sourced)"]
         DynamoDB["DynamoDB<br/>(Event Store)<br/>(LocalStack)"]
     end
 
-    subgraph "Query Side (Read Model)"
+    subgraph "Query Side"
         QueryAPI["Query API<br/>(GraphQL)<br/>Port: 50502"]
         SlickDAOs["Slick DAOs<br/>(Read Model)"]
         PostgreSQL["PostgreSQL<br/>(Read Model)"]

```

## コミット: ef7d22e

### メッセージ

```
chore: Remove LAMBDA_DOCKER_FLAGS from docker-compose-common.yml
```

### 変更されたファイル

- M	docker-compose-common.yml

### 変更内容

```diff
commit ef7d22ea0de33d55eb3e9f6f2ca2d00d22b2837b
Author: Junichi Kato <j5ik2o@gmail.com>
Date:   Tue Nov 18 14:45:32 2025 +0900

    chore: Remove LAMBDA_DOCKER_FLAGS from docker-compose-common.yml

diff --git a/docker-compose-common.yml b/docker-compose-common.yml
index a120fcb..eee96d1 100644
--- a/docker-compose-common.yml
+++ b/docker-compose-common.yml
@@ -38,7 +38,6 @@ services:
       - LAMBDA_LIMITS_CODE_SIZE_ZIPPED=524288000
       - LAMBDA_LIMITS_CODE_SIZE_UNZIPPED=2147483648
       - LAMBDA_LIMITS_CREATE_FUNCTION_REQUEST_SIZE=314572800
-      - LAMBDA_DOCKER_FLAGS=--platform=${DOCKER_DEFAULT_PLATFORM:-linux/amd64}
       - LAMBDA_IGNORE_ARCHITECTURE=1
     volumes:
       - "/var/run/docker.sock:/var/run/docker.sock"

```

## コミット: 2f88b14

### メッセージ

```
docs: Update architecture diagram in README.md for improved clarity and detail
```

### 変更されたファイル

- M	README.md

### 変更内容

```diff
commit 2f88b144e3728f3a40f96aa557d6bd8c98087d25
Author: Junichi Kato <j5ik2o@gmail.com>
Date:   Tue Nov 18 14:35:57 2025 +0900

    docs: Update architecture diagram in README.md for improved clarity and detail

diff --git a/README.md b/README.md
index 2234772..3d3788a 100644
--- a/README.md
+++ b/README.md
@@ -12,37 +12,38 @@ Apache Pekkoを使用したCQRS（Command Query Responsibility Segregation）と
 
 ## アーキテクチャ概要
 
-```
-┌─────────────────────────────────────────────────────────────────┐
-│                         CQRS/ES Architecture                     │
-└─────────────────────────────────────────────────────────────────┘
-
-┌──────────────────┐                        ┌──────────────────┐
-│  Command API     │                        │   Query API      │
-│  (GraphQL)       │                        │   (GraphQL)      │
-│  Port: 50501     │                        │   Port: 50502    │
-└────────┬─────────┘                        └────────┬─────────┘
-         │                                           │
-         │ Mutation                                  │ Query
-         ▼                                           ▼
-┌────────────────────┐                      ┌────────────────────┐
-│  Pekko Actors      │                      │  Slick DAOs        │
-│  (Event Sourced)   │                      │  (Read Model)      │
-└────────┬───────────┘                      └────────▲───────────┘
-         │                                           │
-         │ Events                                    │ Update
-         ▼                                           │
-┌────────────────────┐    DynamoDB Streams   ┌──────┴───────────┐
-│  DynamoDB          │────────────────────────│  Lambda          │
-│  (Event Store)     │                        │  (Read Model     │
-│  (LocalStack)      │                        │   Updater)       │
-└────────────────────┘                        └──────────────────┘
-                                                      │
-                                                      ▼
-                                              ┌──────────────────┐
-                                              │  PostgreSQL      │
-                                              │  (Read Model)    │
-                                              └──────────────────┘
+```mermaid
+graph TB
+    subgraph "Command Side (Write Model)"
+        CommandAPI["Command API<br/>(GraphQL)<br/>Port: 50501"]
+        PekkoActors["Pekko Actors<br/>(Event Sourced)"]
+        DynamoDB["DynamoDB<br/>(Event Store)<br/>(LocalStack)"]
+    end
+
+    subgraph "Query Side (Read Model)"
+        QueryAPI["Query API<br/>(GraphQL)<br/>Port: 50502"]
+        SlickDAOs["Slick DAOs<br/>(Read Model)"]
+        PostgreSQL["PostgreSQL<br/>(Read Model)"]
+    end
+
+    subgraph "Event Processing"
+        Lambda["Lambda<br/>(Read Model Updater)"]
+        Streams["DynamoDB Streams"]
+    end
+
+    CommandAPI -->|Mutation| PekkoActors
+    PekkoActors -->|Events| DynamoDB
+    DynamoDB -->|Stream| Streams
+    Streams -->|Trigger| Lambda
+    Lambda -->|Update| PostgreSQL
+    QueryAPI -->|Query| SlickDAOs
+    SlickDAOs -->|Read| PostgreSQL
+
+    style CommandAPI fill:#e1f5ff
+    style QueryAPI fill:#e1f5ff
+    style DynamoDB fill:#fff4e1
+    style PostgreSQL fill:#fff4e1
+    style Lambda fill:#f0e1ff
 ```
 
 ### データフロー

```

## コミット: 7667625

### メッセージ

```
docs: Update README.md to enhance project description and setup instructions
```

### 変更されたファイル

- M	README.md

### 変更内容

```diff
commit 7667625dec470b1dd6dbc1116689c455fd76867f
Author: Junichi Kato <j5ik2o@gmail.com>
Date:   Tue Nov 18 13:52:30 2025 +0900

    docs: Update README.md to enhance project description and setup instructions

diff --git a/README.md b/README.md
index 5d25c13..2234772 100644
--- a/README.md
+++ b/README.md
@@ -1,74 +1,198 @@
 # pekko-cqrs-es-example
 
-Apache Pekkoを使用したCQRS（Command Query Responsibility Segregation）とEvent Sourcingのサンプル実装です。
+Apache Pekkoを使用したCQRS（Command Query Responsibility Segregation）とEvent Sourcingの実践的なサンプル実装です。
+
+## 特徴
+
+- **完全なCQRS/ESアーキテクチャ**: コマンド側とクエリ側を完全に分離
+- **イベント駆動**: DynamoDB Streamsを使用した非同期イベント処理
+- **ローカル開発環境**: LocalStackを使用したAWSサービスのローカルエミュレーション
+- **GraphQL API**: コマンド側・クエリ側の両方でGraphQL APIを提供
+- **自動化テスト**: E2Eテストスクリプトによる完全なフロー検証
 
 ## アーキテクチャ概要
 
-このプロジェクトは、CQRS+ESパターンを実装したサンプルアプリケーションです。
+```
+┌─────────────────────────────────────────────────────────────────┐
+│                         CQRS/ES Architecture                     │
+└─────────────────────────────────────────────────────────────────┘
+
+┌──────────────────┐                        ┌──────────────────┐
+│  Command API     │                        │   Query API      │
+│  (GraphQL)       │                        │   (GraphQL)      │
+│  Port: 50501     │                        │   Port: 50502    │
+└────────┬─────────┘                        └────────┬─────────┘
+         │                                           │
+         │ Mutation                                  │ Query
+         ▼                                           ▼
+┌────────────────────┐                      ┌────────────────────┐
+│  Pekko Actors      │                      │  Slick DAOs        │
+│  (Event Sourced)   │                      │  (Read Model)      │
+└────────┬───────────┘                      └────────▲───────────┘
+         │                                           │
+         │ Events                                    │ Update
+         ▼                                           │
+┌────────────────────┐    DynamoDB Streams   ┌──────┴───────────┐
+│  DynamoDB          │────────────────────────│  Lambda          │
+│  (Event Store)     │                        │  (Read Model     │
+│  (LocalStack)      │                        │   Updater)       │
+└────────────────────┘                        └──────────────────┘
+                                                      │
+                                                      ▼
+                                              ┌──────────────────┐
+                                              │  PostgreSQL      │
+                                              │  (Read Model)    │
+                                              └──────────────────┘
+```
+
+### データフロー
 
-- **コマンド側（Command API）**: GraphQL経由でコマンドを受け取り、イベントを生成してDynamoDB Journalに保存
-- **イベント処理（Read Model Updater）**: DynamoDBストリームからイベントを取得し、Read Model（PostgreSQL）を更新
-- **クエリ側（Query API）**: GraphQL経由でRead Modelからデータを取得
+1. **コマンド受付**: GraphQL Mutationでコマンドを受け取る（例: `createUserAccount`）
+2. **イベント生成**: Pekkoアクターがドメインロジックを実行し、イベントを生成
+3. **イベント永続化**: イベントをDynamoDB（Event Store）に保存
+4. **イベント配信**: DynamoDB Streamsがイベントを検知
+5. **Read Model更新**: Lambda関数がイベントを処理し、PostgreSQLを更新
+6. **クエリ実行**: GraphQL Queryでデータを取得（例: `getUserAccounts`）
 
 ## 技術スタック
 
-- **言語**: Scala 3
-- **ビルドツール**: SBT
-- **アクターフレームワーク**: Apache Pekko (型付きアクター、永続化、クラスター)
-- **イベントストア**: DynamoDB (Pekko Persistence)
-- **Read Model**: PostgreSQL + Slick
-- **API**: GraphQL (Sangria)
-- **シリアライゼーション**: Protocol Buffers (ScalaPB経由)
-- **イベント処理**: AWS Lambda (DynamoDBストリーム)
+### コア技術
+- **言語**: Scala 3.6.2
+- **ビルドツール**: SBT 1.10.6
+- **アクターフレームワーク**: Apache Pekko 1.1.2 (型付きアクター、永続化、クラスター)
+
+### データストア
+- **イベントストア**: DynamoDB (Pekko Persistence + LocalStack)
+- **Read Model**: PostgreSQL 16 + Slick 3.5.2
+
+### API & シリアライゼーション
+- **API**: GraphQL (Sangria 4.2.4)
+- **シリアライゼーション**: Protocol Buffers (ScalaPB + pekko-protobuf-v3)
+
+### イベント処理
+- **イベント処理基盤**: AWS Lambda (LocalStack)
+- **非同期処理**: DynamoDB Streams
+
+### 開発環境
+- **ローカルAWS環境**: LocalStack 3.x
+- **コンテナ**: Docker & Docker Compose
+- **Java**: OpenJDK 17以降
 
 ## セットアップ
 
 ### 前提条件
 
-- Docker & Docker Compose
-- Java 17以降
-- SBT 1.8以降
+- **Docker & Docker Compose**: LocalStack、PostgreSQL、DynamoDBの実行に必要
+- **Java**: OpenJDK 17以降（推奨: OpenJDK 21）
+- **SBT**: 1.8以降
+- **awslocal CLI**: LocalStackとの対話に使用（オプション）
+
+```bash
+# awslocal のインストール（オプション）
+pip install awscli-local
+```
 
-### ローカル環境の起動
+### クイックスタート
+
+#### 1. リポジトリのクローン
 
 ```bash
-# Docker Composeでインフラを起動
-docker-compose -f docker-compose-common.yml up -d
+git clone https://github.com/j5ik2o/pekko-cqrs-es-example.git
+cd pekko-cqrs-es-example
+```
 
-# DynamoDBテーブルを作成
-cd tools/dynamodb-setup
-make create-tables
+#### 2. 依存関係のインストールとビルド
 
-# データベースマイグレーション（PostgreSQL）
-sbt migrateQuery
+```bash
+# SBTでプロジェクトをビルド
+sbt compile
+
+# Dockerイメージをビルド（Command API、Query API、Read Model Updater）
+sbt dockerBuildAll
+```
 
-# アプリケーションを起動
-# 単一ノードモード
-./scripts/run-single.sh
+#### 3. インフラストラクチャの起動
 
-# またはクラスターモード
-./scripts/run-cluster.sh
+```bash
+# LocalStack、PostgreSQL、DynamoDBを起動し、初期設定を実行
+./scripts/run-single.sh up
+
+# 内部で以下が実行されます：
+# - docker-compose でインフラ起動
+# - DynamoDBテーブル作成
+# - PostgreSQLマイグレーション実行
+# - Lambda関数のデプロイ
+# - Command API、Query APIの起動
 ```
 
-## エンドツーエンド動作例
+起動完了後、以下のサービスが利用可能になります：
 
-### 1. ユーザーアカウントの作成（コマンド側）
+- **Command API (GraphQL)**: http://localhost:50501/api/graphql
+- **Command API Playground**: http://localhost:50501/api/playground
+- **Query API (GraphQL)**: http://localhost:50502/api/graphql
+- **Query API Playground**: http://localhost:50502/api/playground
+- **LocalStack**: http://localhost:4566
+- **PostgreSQL**: localhost:5432
 
-GraphQL Mutationを使用してユーザーアカウントを作成します：
+#### 4. E2Eテストの実行
 
 ```bash
-curl -X POST http://localhost:18080/api/graphql \
-  -H "Content-Type: application/json" \
-  -d '{
-    "query": "mutation CreateUserAccount($input: CreateUserAccountInput!) { createUserAccount(input: $input) { id } }",
-    "variables": {
-      "input": {
-        "firstName": "太郎",
-        "lastName": "山田",
-        "emailAddress": "yamada@example.com"
-      }
-    }
-  }'
+# 完全なCQRS/ESフローをテスト
+./scripts/test-e2e.sh
+
+# 出力例:
+# === Health Check ===
+# ✓ Command API is healthy
+# ✓ Query API is healthy
+# === Step 1: Create UserAccount via GraphQL Mutation ===
+# ✓ UserAccount created successfully!
+# === Step 2: Wait for Event Processing ===
+# ✓ Event processing time elapsed
+# === Step 3: Query UserAccount via GraphQL ===
+# ✓ UserAccount found via GraphQL!
+# ✓ End-to-End test completed successfully!
+```
+
+### 環境の停止とクリーンアップ
+
+```bash
+# アプリケーションとインフラを停止
+./scripts/run-single.sh down
+
+# 全てのデータを削除（ボリューム含む）
+./scripts/run-single.sh down --volumes
+```
+
+## 使い方
+
+### GraphQL Playground を使用した対話的操作
+
+ブラウザでGraphQL Playgroundを開きます：
+
+- **コマンドAPI**: http://localhost:50501/api/playground
+- **クエリAPI**: http://localhost:50502/api/playground
+
+#### 1. ユーザーアカウントの作成（Command API）
+
+Playgroundで以下のMutationを実行：
+
+```graphql
+mutation CreateUserAccount($input: CreateUserAccountInput!) {
+  createUserAccount(input: $input) {
+    id
+  }
+}
+```
+
+Variables:
+```json
+{
+  "input": {
+    "firstName": "太郎",
+    "lastName": "山田",
+    "emailAddress": "yamada@example.com"
+  }
+}
 ```
 
 レスポンス例：
@@ -76,110 +200,508 @@ curl -X POST http://localhost:18080/api/graphql \
 {
   "data": {
     "createUserAccount": {
-      "id": "01HZXXXXXXXXXXXXXX"
+      "id": "01KAAM3Q5PVKKWW1ZSEH6A68FT"
     }
   }
 }
 ```
 
-### 2. Read Modelの更新確認
+#### 2. ユーザーアカウントの取得（Query API）
+
+数秒待ってから、Query API Playgroundで実行：
+
+```graphql
+# 全ユーザーの取得
+{
+  getUserAccounts {
+    id
+    firstName
+    lastName
+    fullName
+    createdAt
+    updatedAt
+  }
+}
+
+# 特定ユーザーの取得
+query GetUserAccount($id: String!) {
+  getUserAccount(userAccountId: $id) {
+    id
+    firstName
+    lastName
+    fullName
+    createdAt
+    updatedAt
+  }
+}
+
+# ユーザー検索
+query SearchUsers($term: String!) {
+  searchUserAccounts(searchTerm: $term) {
+    id
+    firstName
+    lastName
+    fullName
+  }
+}
+```
+
+#### 3. ユーザー名の変更（Command API）
 
-イベントがDynamoDBストリーム経由でRead Model Updaterに処理され、PostgreSQLのRead Modelが更新されます。
-数秒待ってからクエリを実行してください。
+```graphql
+mutation RenameUserAccount($input: RenameUserAccountInput!) {
+  renameUserAccount(input: $input) {
+    id
+  }
+}
+```
 
-### 3. ユーザーアカウントの取得（クエリ側）
+Variables:
+```json
+{
+  "input": {
+    "userAccountId": "01KAAM3Q5PVKKWW1ZSEH6A68FT",
+    "firstName": "次郎",
+    "lastName": "田中"
+  }
+}
+```
+
+#### 4. ユーザーアカウントの削除（Command API）
+
+```graphql
+mutation DeleteUserAccount($input: DeleteUserAccountInput!) {
+  deleteUserAccount(input: $input) {
+    id
+  }
+}
+```
 
-GraphQL Queryを使用してユーザーアカウントを取得します：
+Variables:
+```json
+{
+  "input": {
+    "userAccountId": "01KAAM3Q5PVKKWW1ZSEH6A68FT"
+  }
+}
+```
+
+### curlを使用したコマンドライン操作
+
+#### ユーザーアカウントの作成
 
 ```bash
-# 単一ユーザーの取得
-curl -X POST http://localhost:18082/api/graphql \
+curl -X POST http://localhost:50501/api/graphql \
   -H "Content-Type: application/json" \
   -d '{
-    "query": "query GetUserAccount($id: String!) { getUserAccount(userAccountId: $id) { id firstName lastName fullName createdAt updatedAt } }",
+    "query": "mutation CreateUserAccount($input: CreateUserAccountInput!) { createUserAccount(input: $input) { id } }",
     "variables": {
-      "id": "01HZXXXXXXXXXXXXXX"
+      "input": {
+        "firstName": "太郎",
+        "lastName": "山田",
+        "emailAddress": "yamada@example.com"
+      }
     }
   }'
+```
 
-# 全ユーザーの取得
-curl -X POST http://localhost:18082/api/graphql \
+#### 全ユーザーの取得
+
+```bash
+curl -X POST http://localhost:50502/api/graphql \
   -H "Content-Type: application/json" \
   -d '{
     "query": "{ getUserAccounts { id firstName lastName fullName createdAt updatedAt } }"
   }'
+```
 
-# ユーザー検索
-curl -X POST http://localhost:18082/api/graphql \
+#### 特定ユーザーの取得
+
+```bash
+curl -X POST http://localhost:50502/api/graphql \
   -H "Content-Type: application/json" \
   -d '{
-    "query": "query SearchUsers($term: String!) { searchUserAccounts(searchTerm: $term) { id firstName lastName fullName } }",
+    "query": "query GetUserAccount($id: String!) { getUserAccount(userAccountId: $id) { id firstName lastName fullName } }",
     "variables": {
-      "term": "山田"
+      "id": "01KAAM3Q5PVKKWW1ZSEH6A68FT"
     }
   }'
 ```
 
-レスポンス例：
-```json
-{
-  "data": {
-    "getUserAccount": {
-      "id": "01HZXXXXXXXXXXXXXX",
-      "firstName": "太郎",
-      "lastName": "山田",
-      "fullName": "太郎 山田",
-      "createdAt": "2024-01-01T12:00:00Z",
-      "updatedAt": "2024-01-01T12:00:00Z"
-    }
-  }
-}
+## プロジェクト構造
+
+```
+pekko-cqrs-es-example/
+├── apps/
+│   ├── command-api/              # コマンド側HTTP/GraphQLサーバー
+│   │   └── src/main/
+│   │       ├── resources/
+│   │       │   └── application.conf    # Command API設定
+│   │       └── scala/
+│   │           └── CommandApiMain.scala
+│   ├── query-api/                # クエリ側GraphQLサーバー
+│   │   └── src/main/
+│   │       ├── resources/
+│   │       │   └── application.conf    # Query API設定
+│   │       └── scala/
+│   │           └── QueryApiMain.scala
+│   └── read-model-updater/       # Lambda関数（イベント→Read Model更新）
+│       └── src/main/
+│           ├── resources/
+│           │   └── application.conf    # Lambda設定
+│           └── scala/
+│               └── LambdaHandler.scala
+├── modules/
+│   ├── command/                  # コマンド側モジュール
+│   │   ├── domain/               # ドメインエンティティ、値オブジェクト、イベント
+│   │   │   └── src/main/scala/
+│   │   │       └── users/
+│   │   │           ├── UserAccount.scala          # 集約ルート
+│   │   │           ├── UserAccountEvent.scala     # ドメインイベント
+│   │   │           └── UserAccountId.scala        # 値オブジェクト
+│   │   ├── use-case/             # アプリケーションサービス
+│   │   └── interface-adapter/    # Pekkoアクター、永続化、GraphQLエンドポイント
+│   │       └── src/main/
+│   │           ├── protobuf/     # Protocol Buffer定義
+│   │           └── scala/
+│   │               └── aggregate/
+│   │                   └── UserAccountAggregateActor.scala
+│   ├── query/                    # クエリ側モジュール
+│   │   ├── interface-adapter/    # GraphQL API、Slick DAO
+│   │   │   └── src/main/scala/
+│   │   │       ├── dao/          # Slick DAOs（自動生成）
+│   │   │       └── graphql/      # GraphQL Schema & Resolvers
+│   │   └── flyway-migration/     # データベースマイグレーション
+│   │       └── src/main/resources/db/migration/
+│   └── infrastructure/           # 共有インフラコード
+│       └── src/main/scala/
+│           └── serialization/    # カスタムシリアライザ
+├── scripts/
+│   ├── run-single.sh             # シングルノードモード起動スクリプト
+│   ├── test-e2e.sh               # E2Eテストスクリプト
+│   └── test-graphql.sh           # GraphQLテストスクリプト
+├── tools/
+│   └── dynamodb-setup/           # DynamoDBテーブル定義とセットアップ
+│       ├── Makefile
+│       └── tables.tf
+├── docker-compose-common.yml     # 共通インフラ定義
+├── docker-compose-single.yml     # シングルノードモード定義
+├── build.sbt                     # SBTビルド定義
+└── CLAUDE.md                     # Claude Code向けプロジェクトガイド
 ```
 
-### 4. GraphQL Playgroundを使用
+## 開発ワークフロー
 
-ブラウザでGraphQL Playgroundを開いて、インタラクティブにクエリを実行できます：
+### 1. 新機能の追加
 
-- **コマンドAPI**: http://localhost:18080/api/playground
-- **クエリAPI**: http://localhost:18082/api/playground
+#### ドメインイベントの追加
 
-## プロジェクト構造
+1. `modules/command/domain/src/main/scala/users/UserAccountEvent.scala` にイベントを追加
+2. `modules/command/interface-adapter-contract/src/main/protobuf/` にProtobuf定義を追加
+3. `sbt compile` でProtobufコードを生成
+4. シリアライザを更新（必要に応じて）
+
+#### GraphQL APIの追加
+
+**コマンド側（Mutation）:**
+1. `modules/command/interface-adapter/src/main/scala/graphql/` にスキーマとリゾルバを追加
+
+**クエリ側（Query）:**
+1. `modules/query/flyway-migration/src/main/resources/db/migration/` にマイグレーションを追加
+2. `sbt migrateQuery` でマイグレーション実行
+3. `sbt "queryInterfaceAdapter/generateAllWithDb"` でDAOを再生成
+4. `modules/query/interface-adapter/src/main/scala/graphql/` にスキーマとリゾルバを追加
+
+### 2. コード品質チェック
+
+```bash
+# コードフォーマット
+sbt fmt
 
+# フォーマットとリントのチェック
+sbt lint
+
+# コンパイル
+sbt compile
+
+# テスト実行
+sbt test
+
+# カバレッジ付きテスト
+sbt testCoverage
 ```
-pekko-cqrs-es-example/
-├── apps/
-│   ├── command-api/          # コマンド側HTTP/GraphQLサーバー
-│   ├── query-api/            # クエリ側GraphQLサーバー
-│   └── read-model-updater/   # Lambda関数（イベント→Read Model更新）
-├── modules/
-│   ├── command/              # コマンド側モジュール
-│   │   ├── domain/           # ドメインエンティティ、値オブジェクト、集約
-│   │   ├── use-case/         # アプリケーションサービス、コマンドハンドラ
-│   │   └── interface-adapter/ # Pekkoアクター、永続化、HTTP/gRPCエンドポイント
-│   ├── query/                # クエリ側モジュール
-│   │   └── interface-adapter/ # GraphQL API、Slick DAO、プロジェクション
-│   └── infrastructure/        # 共有インフラコード
-└── tools/
-    └── dynamodb-setup/        # DynamoDBテーブル定義
+
+### 3. データベース操作
+
+```bash
+# マイグレーション実行
+sbt migrateQuery
+
+# マイグレーション情報表示
+sbt infoQuery
+
+# マイグレーション検証
+sbt validateQuery
+
+# クリーン後マイグレーション
+sbt cleanMigrateQuery
+
+# DAO生成（テーブル定義から自動生成）
+sbt "queryInterfaceAdapter/generateAllWithDb"
+```
+
+### 4. 特定モジュールのテスト
+
+```bash
+# コマンドドメインのテスト
+sbt "commandDomain/test"
+
+# クエリインターフェースアダプターのテスト
+sbt "queryInterfaceAdapter/test"
+
+# 特定のテストクラスのみ実行
+sbt "testOnly io.github.j5ik2o.pcqrses.domain.users.UserAccountSpec"
 ```
 
 ## テスト
 
+### 単体テスト
+
 ```bash
-# 単体テスト
+# 全テスト実行
 sbt test
 
-# E2Eテスト
+# カバレッジレポート生成
+sbt testCoverage
+```
+
+### E2Eテスト
+
+```bash
+# 完全なCQRS/ESフローをテスト
+./scripts/test-e2e.sh
+```
+
+E2Eテストスクリプトは以下を自動実行します：
+
+1. **ヘルスチェック**: Command APIとQuery APIの稼働確認
+2. **ユーザー作成**: GraphQL Mutationでユーザーアカウント作成
+3. **イベント処理待機**: Lambda関数がイベントを処理するまで待機
+4. **データ取得**: GraphQL Queryでデータ取得を試行（リトライ機能付き）
+5. **整合性検証**: 作成したデータが正しく取得できることを確認
+
+環境変数でテストの動作をカスタマイズできます：
+
+```bash
+# リトライ回数とタイムアウトのカスタマイズ
+E2E_MAX_RETRIES=15 \
+E2E_RETRY_DELAY=5 \
+E2E_WAIT_AFTER_CREATE=10 \
+./scripts/test-e2e.sh
+
+# 別ホストでテスト
+COMMAND_API_HOST=192.168.1.100 \
+QUERY_API_HOST=192.168.1.100 \
 ./scripts/test-e2e.sh
+```
+
+### GraphQLテスト
 
-# GraphQLテスト
+```bash
+# GraphQL APIの基本動作テスト
 ./scripts/test-graphql.sh
 ```
 
-## ドキュメント
+## トラブルシューティング
+
+### LocalStackが起動しない
+
+```bash
+# LocalStackのログを確認
+docker logs localstack
+
+# LocalStackを再起動
+docker-compose -f docker-compose-common.yml restart localstack
+
+# ヘルスチェック
+curl http://localhost:4566/_localstack/health
+```
+
+### Lambda関数がイベントを処理しない
 
-詳細なドキュメントは `CLAUDE.md` を参照してください。
+```bash
+# Lambda関数のログを確認（CloudWatch Logs）
+awslocal logs tail /aws/lambda/read-model-updater --follow
+
+# DynamoDB Streamsの設定を確認
+awslocal dynamodbstreams list-streams
+
+# Lambda関数のイベントソースマッピングを確認
+awslocal lambda list-event-source-mappings
+```
+
+### PostgreSQLに接続できない
+
+```bash
+# PostgreSQLコンテナのログを確認
+docker logs postgres
+
+# 接続テスト
+psql -h localhost -p 5432 -U postgres -d postgres
+
+# マイグレーション状態を確認
+sbt infoQuery
+```
+
+### DynamoDBにデータが保存されない
+
+```bash
+# テーブルの存在確認
+awslocal dynamodb list-tables
+
+# テーブルの内容確認
+awslocal dynamodb scan --table-name Journal
+
+# テーブル定義の確認
+awslocal dynamodb describe-table --table-name Journal
+```
+
+### ビルドエラーが発生する
+
+```bash
+# クリーンビルド
+sbt clean compile
+
+# 依存関係の更新
+sbt update
+
+# Protobufコードの再生成
+sbt clean compile
+
+# Dockerイメージの再ビルド
+sbt clean dockerBuildAll
+```
+
+### E2Eテストが失敗する
+
+```bash
+# 詳細ログでテストを実行
+bash -x ./scripts/test-e2e.sh
+
+# 待機時間を延長してテスト
+E2E_WAIT_AFTER_CREATE=15 E2E_MAX_RETRIES=20 ./scripts/test-e2e.sh
+
+# 各サービスの状態を確認
+curl http://localhost:50501/api/graphql  # Command API
+curl http://localhost:50502/api/graphql  # Query API
+docker ps                                # 全コンテナの状態
+```
+
+### "ポートが既に使用されています" エラー
+
+```bash
+# ポートを使用しているプロセスを確認
+lsof -i :50501  # Command API
+lsof -i :50502  # Query API
+lsof -i :4566   # LocalStack
+lsof -i :5432   # PostgreSQL
+
+# プロセスを終了
+kill -9 <PID>
+
+# または全て停止してクリーンスタート
+./scripts/run-single.sh down
+./scripts/run-single.sh up
+```
+
+## アーキテクチャの詳細
+
+### イベントソーシング
+
+このプロジェクトでは、全ての状態変更をイベントとして記録します：
+
+1. **コマンド受信**: `CreateUserAccount`
+2. **ドメインロジック実行**: `UserAccount` 集約でビジネスルールを検証
+3. **イベント生成**: `UserAccountEvent.Created_V1`
+4. **イベント永続化**: DynamoDBに保存（Pekko Persistenceが`PersistentRepr`でラップ）
+5. **状態復元**: 過去のイベントを再生して現在の状態を復元可能
+
+### CQRS（コマンドクエリ責任分離）
+
+**コマンド側（書き込み）:**
+- Pekko型付きアクターで集約を実装
+- イベントソーシングで状態を管理
+- DynamoDBをイベントストアとして使用
+- GraphQL Mutationでコマンドを受け付け
+
+**クエリ側（読み取り）:**
+- PostgreSQLに非正規化されたRead Modelを構築
+- Slick DAOで高速なクエリを実現
+- GraphQL Queryでデータを提供
+- Lambda関数でイベントからRead Modelを非同期更新
+
+### Read Model更新の仕組み
+
+1. **イベント検知**: DynamoDB StreamsがJournalテーブルの変更を検知
+2. **Lambda起動**: read-model-updaterが起動
+3. **デシリアライズ**:
+   - `PersistentRepr`をデシリアライズ（Pekkoの内部構造）
+   - ペイロードから実際のイベント（`UserAccountEvent`）を取り出し
+4. **Read Model更新**: PostgreSQLのuser_accountsテーブルを更新
+5. **クエリ可能**: 更新されたデータをQuery APIで取得可能
+
+### Protocol Buffers シリアライゼーション
+
+イベントとスナップショットはProtocol Buffersでシリアライズされます：
+
+- **定義**: `modules/command/interface-adapter-contract/src/main/protobuf/`
+- **生成**: `sbt compile` でScalaコードを自動生成
+- **使用**: Pekko Persistenceのカスタムシリアライザで使用
+- **バージョニング**: イベントスキーマの進化に対応（例: `Created_V1`）
+
+## パフォーマンスとスケーラビリティ
+
+### 水平スケーリング
+
+- **Pekko Cluster**: 複数ノードでアクターを分散（`run-cluster.sh`で実行）
+- **Cluster Sharding**: エンティティIDでアクターを自動分散
+- **イベント処理**: Lambda関数は自動的にスケール
+
+### 最適化ポイント
+
+- **Read Model**: クエリ用に最適化されたスキーマ設計
+- **イベントスナップショット**: 大量イベントからの状態復元を高速化
+- **接続プール**: Slick/HikariCPで効率的なDB接続管理
+- **非同期処理**: イベント処理は完全に非同期
+
+## セキュリティ考慮事項
+
+このサンプルプロジェクトには以下のセキュリティ機能は**含まれていません**：
+
+- 認証・認可
+- API レート制限
+- 入力バリデーション（最小限のみ）
+- 暗号化（転送時・保管時）
+
+本番環境では、これらのセキュリティ対策を必ず実装してください。
 
 ## ライセンス
 
 LICENSEファイルを参照してください。
+
+## 参考資料
+
+- [Apache Pekko](https://pekko.apache.org/)
+- [CQRS Journey](https://docs.microsoft.com/en-us/previous-versions/msp-n-p/jj554200(v=pandp.10))
+- [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)
+- [LocalStack](https://localstack.cloud/)
+- [GraphQL](https://graphql.org/)
+- [Protocol Buffers](https://protobuf.dev/)
+
+## 貢献
+
+プルリクエストを歓迎します。大きな変更の場合は、まずIssueを開いて変更内容を議論してください。
+
+## サポート
+
+問題が発生した場合は、GitHubのIssueを作成してください。

```

## コミット: 54ea358

### メッセージ

```
feat: Implement read model updater with DynamoDB event processing and PostgreSQL integration
```

### 変更されたファイル

- A	.codex/config.toml
- M	README.md
- M	apps/query-api/src/main/resources/pcqrses.conf
- M	apps/read-model-updater/src/main/resources/application.conf
- A	apps/read-model-updater/src/main/resources/pcqrses.conf
- M	apps/read-model-updater/src/main/scala/io/github/j5ik2o/pcqrses/readModelUpdater/LambdaHandler.scala
- M	build.sbt
- M	docker-compose-common.yml
- M	scripts/deploy-lambda-localstack.sh
- M	scripts/test-e2e.sh

### 変更内容

```diff
commit 54ea358d041c6a17f2bbe3fdf2088ecf5007e339
Author: Junichi Kato <j5ik2o@gmail.com>
Date:   Tue Nov 18 13:41:24 2025 +0900

    feat: Implement read model updater with DynamoDB event processing and PostgreSQL integration

diff --git a/.codex/config.toml b/.codex/config.toml
new file mode 100644
index 0000000..11bcf25
--- /dev/null
+++ b/.codex/config.toml
@@ -0,0 +1,3 @@
+model = "gpt-5.1-codex"
+[notice]
+hide_gpt5_1_migration_prompt = true
diff --git a/README.md b/README.md
index 7e1839c..5d25c13 100644
--- a/README.md
+++ b/README.md
@@ -1 +1,185 @@
 # pekko-cqrs-es-example
+
+Apache Pekkoを使用したCQRS（Command Query Responsibility Segregation）とEvent Sourcingのサンプル実装です。
+
+## アーキテクチャ概要
+
+このプロジェクトは、CQRS+ESパターンを実装したサンプルアプリケーションです。
+
+- **コマンド側（Command API）**: GraphQL経由でコマンドを受け取り、イベントを生成してDynamoDB Journalに保存
+- **イベント処理（Read Model Updater）**: DynamoDBストリームからイベントを取得し、Read Model（PostgreSQL）を更新
+- **クエリ側（Query API）**: GraphQL経由でRead Modelからデータを取得
+
+## 技術スタック
+
+- **言語**: Scala 3
+- **ビルドツール**: SBT
+- **アクターフレームワーク**: Apache Pekko (型付きアクター、永続化、クラスター)
+- **イベントストア**: DynamoDB (Pekko Persistence)
+- **Read Model**: PostgreSQL + Slick
+- **API**: GraphQL (Sangria)
+- **シリアライゼーション**: Protocol Buffers (ScalaPB経由)
+- **イベント処理**: AWS Lambda (DynamoDBストリーム)
+
+## セットアップ
+
+### 前提条件
+
+- Docker & Docker Compose
+- Java 17以降
+- SBT 1.8以降
+
+### ローカル環境の起動
+
+```bash
+# Docker Composeでインフラを起動
+docker-compose -f docker-compose-common.yml up -d
+
+# DynamoDBテーブルを作成
+cd tools/dynamodb-setup
+make create-tables
+
+# データベースマイグレーション（PostgreSQL）
+sbt migrateQuery
+
+# アプリケーションを起動
+# 単一ノードモード
+./scripts/run-single.sh
+
+# またはクラスターモード
+./scripts/run-cluster.sh
+```
+
+## エンドツーエンド動作例
+
+### 1. ユーザーアカウントの作成（コマンド側）
+
+GraphQL Mutationを使用してユーザーアカウントを作成します：
+
+```bash
+curl -X POST http://localhost:18080/api/graphql \
+  -H "Content-Type: application/json" \
+  -d '{
+    "query": "mutation CreateUserAccount($input: CreateUserAccountInput!) { createUserAccount(input: $input) { id } }",
+    "variables": {
+      "input": {
+        "firstName": "太郎",
+        "lastName": "山田",
+        "emailAddress": "yamada@example.com"
+      }
+    }
+  }'
+```
+
+レスポンス例：
+```json
+{
+  "data": {
+    "createUserAccount": {
+      "id": "01HZXXXXXXXXXXXXXX"
+    }
+  }
+}
+```
+
+### 2. Read Modelの更新確認
+
+イベントがDynamoDBストリーム経由でRead Model Updaterに処理され、PostgreSQLのRead Modelが更新されます。
+数秒待ってからクエリを実行してください。
+
+### 3. ユーザーアカウントの取得（クエリ側）
+
+GraphQL Queryを使用してユーザーアカウントを取得します：
+
+```bash
+# 単一ユーザーの取得
+curl -X POST http://localhost:18082/api/graphql \
+  -H "Content-Type: application/json" \
+  -d '{
+    "query": "query GetUserAccount($id: String!) { getUserAccount(userAccountId: $id) { id firstName lastName fullName createdAt updatedAt } }",
+    "variables": {
+      "id": "01HZXXXXXXXXXXXXXX"
+    }
+  }'
+
+# 全ユーザーの取得
+curl -X POST http://localhost:18082/api/graphql \
+  -H "Content-Type: application/json" \
+  -d '{
+    "query": "{ getUserAccounts { id firstName lastName fullName createdAt updatedAt } }"
+  }'
+
+# ユーザー検索
+curl -X POST http://localhost:18082/api/graphql \
+  -H "Content-Type: application/json" \
+  -d '{
+    "query": "query SearchUsers($term: String!) { searchUserAccounts(searchTerm: $term) { id firstName lastName fullName } }",
+    "variables": {
+      "term": "山田"
+    }
+  }'
+```
+
+レスポンス例：
+```json
+{
+  "data": {
+    "getUserAccount": {
+      "id": "01HZXXXXXXXXXXXXXX",
+      "firstName": "太郎",
+      "lastName": "山田",
+      "fullName": "太郎 山田",
+      "createdAt": "2024-01-01T12:00:00Z",
+      "updatedAt": "2024-01-01T12:00:00Z"
+    }
+  }
+}
+```
+
+### 4. GraphQL Playgroundを使用
+
+ブラウザでGraphQL Playgroundを開いて、インタラクティブにクエリを実行できます：
+
+- **コマンドAPI**: http://localhost:18080/api/playground
+- **クエリAPI**: http://localhost:18082/api/playground
+
+## プロジェクト構造
+
+```
+pekko-cqrs-es-example/
+├── apps/
+│   ├── command-api/          # コマンド側HTTP/GraphQLサーバー
+│   ├── query-api/            # クエリ側GraphQLサーバー
+│   └── read-model-updater/   # Lambda関数（イベント→Read Model更新）
+├── modules/
+│   ├── command/              # コマンド側モジュール
+│   │   ├── domain/           # ドメインエンティティ、値オブジェクト、集約
+│   │   ├── use-case/         # アプリケーションサービス、コマンドハンドラ
+│   │   └── interface-adapter/ # Pekkoアクター、永続化、HTTP/gRPCエンドポイント
+│   ├── query/                # クエリ側モジュール
+│   │   └── interface-adapter/ # GraphQL API、Slick DAO、プロジェクション
+│   └── infrastructure/        # 共有インフラコード
+└── tools/
+    └── dynamodb-setup/        # DynamoDBテーブル定義
+```
+
+## テスト
+
+```bash
+# 単体テスト
+sbt test
+
+# E2Eテスト
+./scripts/test-e2e.sh
+
+# GraphQLテスト
+./scripts/test-graphql.sh
+```
+
+## ドキュメント
+
+詳細なドキュメントは `CLAUDE.md` を参照してください。
+
+## ライセンス
+
+LICENSEファイルを参照してください。
diff --git a/apps/query-api/src/main/resources/pcqrses.conf b/apps/query-api/src/main/resources/pcqrses.conf
index 948cd36..1beb4da 100644
--- a/apps/query-api/src/main/resources/pcqrses.conf
+++ b/apps/query-api/src/main/resources/pcqrses.conf
@@ -2,14 +2,14 @@ pcqrses {
   query-api {
     host = "0.0.0.0"
     host = ${?QUERY_API_HOST}
-    port = 9002
+    port = 18082
     port = ${?QUERY_API_PORT}
     shutdown-timeout = 30 seconds
   }
 
   database {
     driver = "org.postgresql.Driver"
-    url = "jdbc:postgresql://localhost:5432/pcqrses_db"
+    url = "jdbc:postgresql://localhost:5432/p-cqrs-es_development"
     url = ${?DATABASE_URL}
     user = "postgres"
     user = ${?DATABASE_USER}
diff --git a/apps/read-model-updater/src/main/resources/application.conf b/apps/read-model-updater/src/main/resources/application.conf
index e69de29..513cd7f 100644
--- a/apps/read-model-updater/src/main/resources/application.conf
+++ b/apps/read-model-updater/src/main/resources/application.conf
@@ -0,0 +1,68 @@
+include "pcqrses.conf"
+
+pekko {
+  stdout-loglevel = "INFO"
+
+  actor {
+    provider = "local"
+  }
+
+  loggers = ["org.apache.pekko.event.slf4j.Slf4jLogger"]
+  loglevel = "INFO"
+  loglevel = ${?PEKKO_LOG_LEVEL}
+  logging-filter = "org.apache.pekko.event.slf4j.Slf4jLoggingFilter"
+
+  log-dead-letters = 10
+  log-dead-letters-during-shutdown = on
+
+  persistence {
+    journal {
+      plugin = "pekko.persistence.journal.inmem"
+      inmem {
+        class = "org.apache.pekko.persistence.journal.inmem.InmemJournal"
+        plugin-dispatcher = "pekko.actor.default-dispatcher"
+      }
+    }
+  }
+
+  serialization-bindings {
+    "io.github.j5ik2o.pcqrses.command.domain.users.UserAccountEvent" = user-account-event
+  }
+
+  serializers {
+    user-account-event = "io.github.j5ik2o.pcqrses.command.interfaceAdapter.aggregate.users.UserAccountEventSerializer"
+  }
+
+  serialization-identifiers {
+    "io.github.j5ik2o.pcqrses.command.interfaceAdapter.aggregate.users.UserAccountEventSerializer" = 20002
+  }
+}
+
+read-model-updater {
+  timeouts {
+    database-operation = 30 seconds
+    database-operation = ${?READ_MODEL_UPDATER_DB_TIMEOUT}
+    system-termination = 10 seconds
+    system-termination = ${?READ_MODEL_UPDATER_TERMINATION_TIMEOUT}
+  }
+  
+  slick {
+    profile = "slick.jdbc.PostgresProfile$"
+    db {
+      driver = "org.postgresql.Driver"
+      url = "jdbc:postgresql://localhost:5432/p-cqrs-es_development"
+      url = ${?DATABASE_URL}
+      user = "postgres"
+      user = ${?DATABASE_USER}
+      password = "postgres"
+      password = ${?DATABASE_PASSWORD}
+      connectionPool = "HikariCP"
+      numThreads = 20
+      maxConnections = 20
+      minConnections = 5
+      connectionTimeout = 30000
+      idleTimeout = 600000
+      maxLifetime = 1800000
+    }
+  }
+}
diff --git a/apps/read-model-updater/src/main/resources/pcqrses.conf b/apps/read-model-updater/src/main/resources/pcqrses.conf
new file mode 100644
index 0000000..612aeaa
--- /dev/null
+++ b/apps/read-model-updater/src/main/resources/pcqrses.conf
@@ -0,0 +1,18 @@
+pcqrses {
+  database {
+    driver = "org.postgresql.Driver"
+    url = "jdbc:postgresql://localhost:5432/p-cqrs-es_development"
+    url = ${?DATABASE_URL}
+    user = "postgres"
+    user = ${?DATABASE_USER}
+    password = "postgres"
+    password = ${?DATABASE_PASSWORD}
+    connectionPool = "HikariCP"
+    numThreads = 20
+    maxConnections = 20
+    minConnections = 5
+    connectionTimeout = 30000
+    idleTimeout = 600000
+    maxLifetime = 1800000
+  }
+}
diff --git a/apps/read-model-updater/src/main/scala/io/github/j5ik2o/pcqrses/readModelUpdater/LambdaHandler.scala b/apps/read-model-updater/src/main/scala/io/github/j5ik2o/pcqrses/readModelUpdater/LambdaHandler.scala
index a13cc8a..7836207 100644
--- a/apps/read-model-updater/src/main/scala/io/github/j5ik2o/pcqrses/readModelUpdater/LambdaHandler.scala
+++ b/apps/read-model-updater/src/main/scala/io/github/j5ik2o/pcqrses/readModelUpdater/LambdaHandler.scala
@@ -2,34 +2,246 @@ package io.github.j5ik2o.pcqrses.readModelUpdater
 
 import com.amazonaws.services.lambda.runtime.{Context, RequestHandler}
 import com.amazonaws.services.lambda.runtime.events.DynamodbEvent
+import com.amazonaws.services.lambda.runtime.events.DynamodbEvent.DynamodbStreamRecord
 import com.fasterxml.jackson.databind.ObjectMapper
 import com.fasterxml.jackson.module.scala.DefaultScalaModule
 import com.typesafe.config.ConfigFactory
+import io.github.j5ik2o.pcqrses.command.domain.users.UserAccountEvent
+import io.github.j5ik2o.pcqrses.query.interfaceAdapter.dao.UserAccountsComponent
 import org.apache.pekko.actor.ActorSystem
+import org.apache.pekko.persistence.PersistentRepr
 import org.apache.pekko.serialization.SerializationExtension
 import org.slf4j.LoggerFactory
 import slick.basic.DatabaseConfig
 import slick.jdbc.JdbcProfile
 
-import scala.concurrent.duration.DurationLong
+import java.nio.ByteBuffer
+import java.sql.Timestamp
+import scala.concurrent.duration.Duration
+import scala.concurrent.Await
+import scala.util.Try
 
 class LambdaHandler extends RequestHandler[DynamodbEvent, LambdaResponse] {
-  LoggerFactory.getLogger(getClass)
+
+  private val logger = LoggerFactory.getLogger(getClass)
 
   private val objectMapper = new ObjectMapper()
   objectMapper.registerModule(DefaultScalaModule)
 
   private val config = ConfigFactory.load()
   private lazy val system = ActorSystem("read-model-updater", config)
-  SerializationExtension(system)
+  private lazy val serialization = SerializationExtension(system)
 
-  config.getDuration("read-model-updater.timeouts.database-operation").getSeconds.seconds
+  private val databaseOperationTimeout: Duration =
+    Duration.fromNanos(config.getDuration("read-model-updater.timeouts.database-operation").toNanos)
 
-  config.getDuration("read-model-updater.timeouts.system-termination").getSeconds.seconds
   private val databaseConfig: DatabaseConfig[JdbcProfile] =
     DatabaseConfig.forConfig[JdbcProfile]("read-model-updater.slick", config)
-  databaseConfig.db
-  val profile: slick.jdbc.JdbcProfile = databaseConfig.profile
 
-  override def handleRequest(input: DynamodbEvent, context: Context): LambdaResponse = ???
+  private val UserAccountEntityTypePrefix = "UserAccount-"
+
+  override def handleRequest(input: DynamodbEvent, context: Context): LambdaResponse = {
+    try {
+      logger.info(s"Received DynamoDB event with ${input.getRecords.size} records")
+
+      val results = input.getRecords.asScala.map(processRecord).toList
+
+      val failures = results.collect { case Left(error) => error }
+      val successes = results.collect { case Right(_) => () }
+
+      if (failures.nonEmpty) {
+        logger.error(s"Failed to process ${failures.size} out of ${results.size} records")
+        failures.foreach { error =>
+          logger.error(s"Processing error: ${error.message}", error.exception.orNull)
+        }
+        LambdaResponse(
+          statusCode = 207, // Multi-Status
+          body = objectMapper.writeValueAsString(
+            ResponseBody(
+              message = s"Processed ${successes.size} records successfully, ${failures.size} failed",
+              error = Some(failures.map(_.message).mkString("; "))
+            )
+          )
+        )
+      } else {
+        logger.info(s"Successfully processed ${successes.size} records")
+        LambdaResponse(
+          statusCode = 200,
+          body = objectMapper.writeValueAsString(
+            ResponseBody(message = s"Successfully processed ${successes.size} records")
+          )
+        )
+      }
+    } catch {
+      case ex: Exception =>
+        logger.error("Unexpected error processing DynamoDB event", ex)
+        LambdaResponse(
+          statusCode = 500,
+          body = objectMapper.writeValueAsString(
+            ResponseBody(message = "Internal server error", error = Some(ex.getMessage))
+          )
+        )
+    }
+  }
+
+  private def processRecord(record: DynamodbStreamRecord): Either[ProcessingError, Unit] = {
+    try {
+      val tableName = record.getEventSourceARN.split("/")(1)
+      if (tableName != "Journal") {
+        logger.debug(s"Skipping record from table: $tableName")
+        return Right(())
+      }
+
+      val newImage = Option(record.getDynamodb.getNewImage)
+      if (newImage.isEmpty) {
+        logger.debug("Skipping record without NewImage (likely DELETE event)")
+        return Right(())
+      }
+
+      val attributes = newImage.get.asScala
+
+      val persistenceIdOpt = Option(attributes.get("persistence-id"))
+        .flatMap(attrOpt => Option(attrOpt.map(_.getS).orNull))
+
+      if (persistenceIdOpt.isEmpty || !persistenceIdOpt.get.startsWith(UserAccountEntityTypePrefix)) {
+        logger.debug(s"Skipping record with persistence-id: ${persistenceIdOpt.getOrElse("null")}")
+        return Right(())
+      }
+
+      val messageAttrOpt = attributes.get("message")
+      if (messageAttrOpt.isEmpty) {
+        logger.warn("Record missing message attribute")
+        return Left(ProcessingError("Missing message attribute", None))
+      }
+      val messageAttr = messageAttrOpt.get
+      logger.info(s"Message attribute type: B=${messageAttr.getB != null}, BS=${messageAttr.getBS != null}, S=${messageAttr.getS != null}")
+
+      val serializerIdAttrOpt = attributes.get("serializer-id")
+      val manifestAttrOpt = attributes.get("manifest")
+
+      val messageBytes = Option(messageAttr.getB) match {
+        case Some(binaryData) =>
+          convertToBytes(binaryData)
+        case None =>
+          throw new IllegalArgumentException("Message attribute B (binary) is required")
+      }
+
+      // PersistentRepr からイベントを取り出して処理
+      deserializePersistentReprAndProcess(messageBytes)
+    } catch {
+      case ex: Exception =>
+        logger.error("Error processing record", ex)
+        Left(ProcessingError(s"Error processing record: ${ex.getMessage}", Some(ex)))
+    }
+  }
+
+  private def convertToBytes(binaryData: ByteBuffer): Array[Byte] = {
+    val bytes = if (binaryData.hasArray) {
+      binaryData.array()
+    } else {
+      val arr = new Array[Byte](binaryData.remaining())
+      binaryData.get(arr)
+      arr
+    }
+    logger.debug(s"Converted ByteBuffer to ${bytes.length} bytes")
+    bytes
+  }
+
+  private def deserializePersistentRepr(bytes: Array[Byte]): Try[PersistentRepr] = Try {
+    val persistentReprSerializer = serialization.serializerFor(classOf[PersistentRepr])
+    logger.info(s"Using PersistentRepr serializer: ${persistentReprSerializer.getClass.getName} (ID: ${persistentReprSerializer.identifier})")
+    persistentReprSerializer.fromBinary(bytes, classOf[PersistentRepr]).asInstanceOf[PersistentRepr]
+  }
+
+  private def deserializePersistentReprAndProcess(bytes: Array[Byte]): Either[ProcessingError, Unit] = {
+    try {
+      logger.debug(s"Binary data size: ${bytes.length} bytes")
+
+      // PersistentRepr をデシリアライズ
+      deserializePersistentRepr(bytes) match {
+        case scala.util.Success(persistentRepr) =>
+          logger.debug(s"Successfully deserialized PersistentRepr:")
+          logger.debug(s"  Persistence ID: ${persistentRepr.persistenceId}")
+          logger.debug(s"  Sequence Nr: ${persistentRepr.sequenceNr}")
+          logger.debug(s"  Manifest: ${persistentRepr.manifest}")
+
+          // ペイロード（実際のイベント）を取り出す
+          persistentRepr.payload match {
+            case event: UserAccountEvent =>
+              logger.info(s"Processing UserAccountEvent: ${event.getClass.getSimpleName} for entity: ${event.entityId.asString}")
+              processUserAccountEvent(event)
+            case other =>
+              logger.warn(s"Unknown event type: ${other.getClass.getName}")
+              Right(())
+          }
+
+        case scala.util.Failure(ex) =>
+          logger.error(s"Failed to deserialize PersistentRepr: ${ex.getMessage}", ex)
+          Left(ProcessingError(s"Error deserializing PersistentRepr: ${ex.getMessage}", Some(ex)))
+      }
+    } catch {
+      case ex: Exception =>
+        logger.error("Error processing PersistentRepr", ex)
+        Left(ProcessingError(s"Error processing PersistentRepr: ${ex.getMessage}", Some(ex)))
+    }
+  }
+
+  private def processUserAccountEvent(event: UserAccountEvent): Either[ProcessingError, Unit] = {
+    try {
+      val db = databaseConfig.db
+      val component = new UserAccountsComponent {
+        override val profile: JdbcProfile = databaseConfig.profile
+      }
+      import databaseConfig.profile.api._
+
+      val action = event match {
+        case UserAccountEvent.Created_V1(_, entityId, name, _, occurredAt) =>
+          val record = component.UserAccountsRecord(
+            id = entityId.asString,
+            firstName = name.breachEncapsulationOfFirstName.asString,
+            lastName = name.breachEncapsulationOfLastName.asString,
+            createdAt = Timestamp.from(occurredAt.asInstant()),
+            updatedAt = Timestamp.from(occurredAt.asInstant())
+          )
+          component.UserAccountsDao.insertOrUpdate(record)
+
+        case UserAccountEvent.Renamed_V1(_, entityId, _, newName, occurredAt) =>
+          component.UserAccountsDao
+            .filter(_.id === entityId.asString)
+            .map(r => (r.firstName, r.lastName, r.updatedAt))
+            .update(
+              (newName.breachEncapsulationOfFirstName.asString,
+                newName.breachEncapsulationOfLastName.asString,
+                Timestamp.from(occurredAt.asInstant()))
+            )
+
+        case UserAccountEvent.Deleted_V1(_, entityId, _) =>
+          component.UserAccountsDao.filter(_.id === entityId.asString).delete
+      }
+
+      val result = Await.result(db.run(action), databaseOperationTimeout)
+      logger.debug(s"Successfully processed event: ${event.getClass.getSimpleName} for entity: ${event.entityId.asString}")
+      Right(())
+    } catch {
+      case ex: Exception =>
+        logger.error(s"Error processing UserAccountEvent: ${event.getClass.getSimpleName}", ex)
+        Left(ProcessingError(s"Error processing event: ${ex.getMessage}", Some(ex)))
+    }
+  }
+
+  private case class ProcessingError(message: String, exception: Option[Throwable])
+
+  private implicit class ScalaMapConverter[A, B](map: java.util.Map[A, B]) {
+    def asScala: scala.collection.mutable.Map[A, B] = {
+      import scala.jdk.CollectionConverters._
+      map.asScala
+    }
+  }
+
+  private implicit class JavaListConverter[A](list: java.util.List[A]) {
+    def asScala: scala.collection.mutable.Buffer[A] = {
+      import scala.jdk.CollectionConverters._
+      list.asScala
+    }
+  }
 }
diff --git a/build.sbt b/build.sbt
index 291384e..b614911 100644
--- a/build.sbt
+++ b/build.sbt
@@ -366,14 +366,14 @@ lazy val readModelUpdater = (project in file("apps/read-model-updater"))
     Docker / packageName := s"${basename}-read-model-updater",
     Docker / version := "0.1.0",
     dockerBaseImage := "eclipse-temurin:17-jre-focal",
-    // AWS Lambda用の設定（仮）
-    // FIXME: インフラストラクチャーに設定ファイルを置くのはよくない…。あとで直す
+    // AWS Lambda用の設定
     Universal / mappings += file(
-      "modules/infrastructure/src/main/resources/application.conf") -> "conf/application.conf",
+      "apps/read-model-updater/src/main/resources/application.conf") -> "conf/application.conf",
     Universal / javaOptions ++= Seq("-Dconfig.file=conf/application.conf"),
     assembly / assemblyJarName := "read-model-updater-lambda.jar",
     assembly / mainClass := Some(s"io.github.j5ik2o.${basename}.readModelUpdater.LambdaHandler"),
     assembly / assemblyMergeStrategy := {
+      case PathList("META-INF", "services", xs @ _*) => MergeStrategy.concat
       case PathList("META-INF", xs @ _*) => MergeStrategy.discard
       case PathList("reference.conf") => MergeStrategy.concat
       case PathList("application.conf") => MergeStrategy.concat
@@ -411,8 +411,8 @@ lazy val readModelUpdater = (project in file("apps/read-model-updater"))
         name.contains("pekko-persistence-journal") ||
         name.contains("pekko-persistence-snapshot") ||
         name.contains("pekko-testkit") ||
-        name.contains("pekko-slf4j") ||
-        // pekko-protobuf-v3は必要なので除外しない
+        // pekko-slf4jは必要なので除外しない（Slf4jLoggingFilter使用）
+        // pekko-protobuf-v3は必要（PersistentReprのデシリアライズに使用）
         (name.contains("pekko-protobuf") && !name.contains("pekko-protobuf-v3")) ||
         // 大きくて不要な一部ライブラリのみ除外（DB関連は含める）
         name.contains("flyway") ||
@@ -446,9 +446,10 @@ lazy val readModelUpdater = (project in file("apps/read-model-updater"))
       apachePekko.actorTyped,
       apachePekko.persistenceTyped,
       apachePekko.serializationJackson,
+      apachePekko.slf4j,
       apachePekko.remote,
-      apachePekko.stream,
-      apachePekko.protobufV3
+      apachePekko.stream
+      // apachePekko.protobufV3 を除外 - ScalaPBのGoogle Protobufと競合するため
     )
   )
   .dependsOn(commandDomain, commandInterfaceAdapterEventSerializer, queryInterfaceAdapter)
diff --git a/docker-compose-common.yml b/docker-compose-common.yml
index 418e2dd..a120fcb 100644
--- a/docker-compose-common.yml
+++ b/docker-compose-common.yml
@@ -17,6 +17,7 @@ services:
   localstack:
     image: localstack/localstack:4.7
     hostname: localstack
+    privileged: true
     ports:
       - "${DOCKER_LOCALSTACK_PORT:-50503}:4566"
     environment:
@@ -27,13 +28,13 @@ services:
       - AWS_DEFAULT_REGION=ap-northeast-1
       - AWS_ACCESS_KEY_ID=dummy
       - AWS_SECRET_ACCESS_KEY=dummy
-      - LAMBDA_DOCKER_NETWORK=p-cqrs-es_back_p-cqrs-es-network
+      - LAMBDA_DOCKER_NETWORK=pekko-cqrs-es-example_p-cqrs-es-network
       - AWS_ENDPOINT_URL=http://localstack:4566
       - LOCALSTACK_HOST=localstack
       - HOSTNAME_FROM_LAMBDA=localstack
       - LAMBDA_DOCKER_DNS=127.0.0.11
       - LAMBDA_RUNTIME_ENVIRONMENT_TIMEOUT=60
-      - LAMBDA_REMOVE_CONTAINERS=true
+      - LAMBDA_REMOVE_CONTAINERS=false
       - LAMBDA_LIMITS_CODE_SIZE_ZIPPED=524288000
       - LAMBDA_LIMITS_CODE_SIZE_UNZIPPED=2147483648
       - LAMBDA_LIMITS_CREATE_FUNCTION_REQUEST_SIZE=314572800
diff --git a/scripts/deploy-lambda-localstack.sh b/scripts/deploy-lambda-localstack.sh
index 90eb471..f6ff481 100755
--- a/scripts/deploy-lambda-localstack.sh
+++ b/scripts/deploy-lambda-localstack.sh
@@ -126,7 +126,7 @@ ENV_JSON_FILE="/tmp/lambda-env.json"
 cat > $ENV_JSON_FILE << 'EOF'
 {
   "Variables": {
-    "DATABASE_URL": "jdbc:postgresql://postgres:5432/pcqrses_development",
+    "DATABASE_URL": "jdbc:postgresql://postgres:5432/p-cqrs-es_development",
     "DATABASE_USER": "postgres",
     "DATABASE_PASSWORD": "postgres",
     "AWS_DEFAULT_REGION": "ap-northeast-1",
diff --git a/scripts/test-e2e.sh b/scripts/test-e2e.sh
index 8cfcc8c..0567a6c 100755
--- a/scripts/test-e2e.sh
+++ b/scripts/test-e2e.sh
@@ -1,7 +1,7 @@
 #!/bin/bash
 
-# End-to-End Test: Create Staff via gRPC and Query via GraphQL
-# このスクリプトは、gRPC経由でスタッフを作成し、GraphQL経由で取得するE2Eテストを実行します
+# End-to-End Test: Create UserAccount via GraphQL and Query via GraphQL
+# このスクリプトは、GraphQL Mutation経由でユーザーアカウントを作成し、GraphQL Query経由で取得するE2Eテストを実行します
 
 set -e
 
@@ -11,21 +11,19 @@ E2E_MAX_RETRIES="${E2E_MAX_RETRIES:-10}"
 E2E_RETRY_DELAY="${E2E_RETRY_DELAY:-3}"
 E2E_WAIT_AFTER_CREATE="${E2E_WAIT_AFTER_CREATE:-8}"
 
-GRPC_HOST="${GRPC_HOST:-localhost}"
-GRPC_PORT="${GRPC_PORT:-50501}"
-GRAPHQL_HOST="${GRAPHQL_HOST:-localhost}"
-GRAPHQL_PORT="${GRAPHQL_PORT:-50502}"
-GRAPHQL_ENDPOINT="http://$GRAPHQL_HOST:$GRAPHQL_PORT/graphql"
-GRPCURL_IMAGE="fullstorydev/grpcurl:latest"
+COMMAND_API_HOST="${COMMAND_API_HOST:-localhost}"
+COMMAND_API_PORT="${COMMAND_API_PORT:-50501}"
+COMMAND_API_ENDPOINT="http://$COMMAND_API_HOST:$COMMAND_API_PORT/api/graphql"
+
+QUERY_API_HOST="${QUERY_API_HOST:-localhost}"
+QUERY_API_PORT="${QUERY_API_PORT:-50502}"
+QUERY_API_ENDPOINT="http://$QUERY_API_HOST:$QUERY_API_PORT/api/graphql"
 
 # テストデータ生成用のタイムスタンプ
 TIMESTAMP=$(date +%s)
-TEST_STAFF_NO="TEST${TIMESTAMP}"
-TEST_GIVEN_NAME="太郎"
-TEST_FAMILY_NAME="テスト"
+TEST_FIRST_NAME="太郎${TIMESTAMP}"
+TEST_LAST_NAME="テスト"
 TEST_EMAIL="test${TIMESTAMP}@example.com"
-TEST_BIRTHDAY="1990-01-15"
-TEST_HIRED_DATE="2024-04-01"
 
 # 色付き出力用の関数
 print_header() {
@@ -48,19 +46,11 @@ print_json() {
     echo "$1" | jq '.' 2>/dev/null || echo "$1"
 }
 
-# grpcurlコマンドを実行する関数
-run_grpcurl() {
-    docker run --rm \
-        --network host \
-        $GRPCURL_IMAGE \
-        -plaintext \
-        "$@"
-}
-
 # GraphQL クエリを実行する関数
 execute_graphql() {
-    local query="$1"
-    local variables="${2:-{}}"
+    local endpoint="$1"
+    local query="$2"
+    local variables="${3:-{}}"
 
     # クエリ内の改行をスペースに置換
     query=$(echo "$query" | tr '\n' ' ' | sed 's/  */ /g')
@@ -80,28 +70,31 @@ execute_graphql() {
     curl -s -X POST \
         -H "Content-Type: application/json" \
         -d "$payload" \
-        "$GRAPHQL_ENDPOINT"
+        "$endpoint"
 }
 
 # ヘルスチェック
 health_check() {
     print_header "Health Check"
-    
-    # gRPC Health Check
-    print_info "Checking Command API (gRPC) health..."
-    if run_grpcurl $GRPC_HOST:$GRPC_PORT list > /dev/null 2>&1; then
+
+    # Command API Health Check
+    print_info "Checking Command API (GraphQL) health..."
+    RESPONSE=$(curl -s -w "\n%{http_code}" "$COMMAND_API_ENDPOINT")
+    HTTP_CODE=$(echo "$RESPONSE" | tail -n 1)
+
+    if [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "400" ]; then
         print_success "Command API is healthy"
     else
-        print_error "Command API is not responding"
+        print_error "Command API health check failed (HTTP $HTTP_CODE)"
         exit 1
     fi
-    
-    # GraphQL Health Check
+
+    # Query API Health Check
     print_info "Checking Query API (GraphQL) health..."
-    RESPONSE=$(curl -s -w "\n%{http_code}" "http://$GRAPHQL_HOST:$GRAPHQL_PORT/health")
+    RESPONSE=$(curl -s -w "\n%{http_code}" "$QUERY_API_ENDPOINT")
     HTTP_CODE=$(echo "$RESPONSE" | tail -n 1)
-    
-    if [ "$HTTP_CODE" = "200" ]; then
+
+    if [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "400" ]; then
         print_success "Query API is healthy"
     else
         print_error "Query API health check failed (HTTP $HTTP_CODE)"
@@ -109,42 +102,50 @@ health_check() {
     fi
 }
 
-# Step 1: Create Staff via gRPC
-create_staff_via_grpc() {
-    print_header "Step 1: Create Staff via gRPC"
-    print_info "Creating staff with the following details:"
-    echo "  - Staff No: $TEST_STAFF_NO"
-    echo "  - Name: $TEST_FAMILY_NAME $TEST_GIVEN_NAME"
+# Step 1: Create UserAccount via GraphQL Mutation
+create_user_account_via_graphql() {
+    print_header "Step 1: Create UserAccount via GraphQL Mutation"
+    print_info "Creating user account with the following details:"
+    echo "  - First Name: $TEST_FIRST_NAME"
+    echo "  - Last Name: $TEST_LAST_NAME"
     echo "  - Email: $TEST_EMAIL"
-    echo "  - Birthday: $TEST_BIRTHDAY"
-    echo "  - Hired Date: $TEST_HIRED_DATE"
     echo ""
-    
-    # CreateStaffリクエストを送信
-    RESPONSE=$(run_grpcurl \
-        -format text \
-        -d "staff_no:\"$TEST_STAFF_NO\" given_name:\"$TEST_GIVEN_NAME\" family_name:\"$TEST_FAMILY_NAME\" email:\"$TEST_EMAIL\" birthday:\"$TEST_BIRTHDAY\" hired_date:\"$TEST_HIRED_DATE\"" \
-        $GRPC_HOST:$GRPC_PORT \
-        io.github.j5ik2o.pcqrses.proto.staff.StaffService/CreateStaff 2>&1) || true
-    
+
+    # CreateUserAccount Mutationを実行
+    local mutation='mutation CreateUserAccount($input: CreateUserAccountInput!) {
+        createUserAccount(input: $input) {
+            id
+        }
+    }'
+
+    local variables="{
+        \"input\": {
+            \"firstName\": \"$TEST_FIRST_NAME\",
+            \"lastName\": \"$TEST_LAST_NAME\",
+            \"emailAddress\": \"$TEST_EMAIL\"
+        }
+    }"
+
+    RESPONSE=$(execute_graphql "$COMMAND_API_ENDPOINT" "$mutation" "$variables")
+
     echo "$RESPONSE"
-    
+
     # レスポンスの確認
-    if echo "$RESPONSE" | grep -q "ERROR"; then
-        if echo "$RESPONSE" | grep -q "AlreadyExists"; then
-            print_error "Staff with StaffNo $TEST_STAFF_NO already exists"
+    if echo "$RESPONSE" | jq -e '.data.createUserAccount.id' > /dev/null 2>&1; then
+        CREATED_USER_ID=$(echo "$RESPONSE" | jq -r '.data.createUserAccount.id')
+        print_success "UserAccount created successfully!"
+        print_info "Created UserAccount ID: $CREATED_USER_ID"
+        return 0
+    elif echo "$RESPONSE" | jq -e '.errors' > /dev/null 2>&1; then
+        ERROR_MSG=$(echo "$RESPONSE" | jq -r '.errors[0].message')
+        if echo "$ERROR_MSG" | grep -q -i "already exists"; then
+            print_error "UserAccount with email $TEST_EMAIL already exists"
             print_info "This might be from a previous test run. Continuing with query test..."
             return 0
         else
-            print_error "Failed to create staff"
+            print_error "Failed to create user account: $ERROR_MSG"
             return 1
         fi
-    elif echo "$RESPONSE" | grep -q "staff_id:"; then
-        # スタッフIDを抽出
-        CREATED_STAFF_ID=$(echo "$RESPONSE" | grep -o 'staff_id: *"[^"]*"' | sed 's/.*: *"\([^"]*\)".*/\1/')
-        print_success "Staff created successfully!"
-        print_info "Created Staff ID: $CREATED_STAFF_ID"
-        return 0
     else
         print_error "Unexpected response"
         return 1
@@ -155,7 +156,7 @@ create_staff_via_grpc() {
 wait_for_consistency() {
     print_header "Step 2: Wait for Event Processing"
     print_info "Waiting for DynamoDB stream to process and update PostgreSQL..."
-    
+
     # Lambda関数がイベントを処理するまで待機
     local wait_time=$E2E_WAIT_AFTER_CREATE
     for i in $(seq $wait_time -1 1); do
@@ -166,46 +167,70 @@ wait_for_consistency() {
     print_success "Event processing time elapsed"
 }
 
-# Step 3: Query Staff via GraphQL
-query_staff_via_graphql() {
-    print_header "Step 3: Query Staff via GraphQL"
-    
-    # 3.1: Query by StaffNo
-    print_info "Querying staff by StaffNo: $TEST_STAFF_NO"
-    
-    local query='query GetStaff($staffNo: String!) { 
-        staffByNo(staffNo: $staffNo) { 
-            id 
-            staffNo 
-            globalFamilyName 
-            globalGivenName 
-            localFamilyName 
-            localGivenName 
-            nameLocale 
-            createdAt 
-            updatedAt 
-        } 
+# Step 3: Query UserAccount via GraphQL
+query_user_account_via_graphql() {
+    print_header "Step 3: Query UserAccount via GraphQL"
+
+    # 3.1: Query all user accounts
+    print_info "Querying all user accounts to find created user..."
+
+    local query='{
+        getUserAccounts {
+            id
+            firstName
+            lastName
+            fullName
+            createdAt
+            updatedAt
+        }
     }'
-    
-    local variables="{\"staffNo\": \"$TEST_STAFF_NO\"}"
-    
-    RESPONSE=$(execute_graphql "$query" "$variables")
-    
-    if echo "$RESPONSE" | jq -e '.data.staffByNo' > /dev/null 2>&1; then
-        STAFF_DATA=$(echo "$RESPONSE" | jq '.data.staffByNo')
-        if [ "$STAFF_DATA" != "null" ]; then
-            print_success "Staff found via GraphQL!"
-            print_json "$RESPONSE"
-            
+
+    RESPONSE=$(execute_graphql "$QUERY_API_ENDPOINT" "$query")
+
+    if echo "$RESPONSE" | jq -e '.data.getUserAccounts' > /dev/null 2>&1; then
+        # テストユーザーが含まれているか確認
+        USER_DATA=$(echo "$RESPONSE" | jq ".data.getUserAccounts[] | select(.firstName == \"$TEST_FIRST_NAME\" and .lastName == \"$TEST_LAST_NAME\")")
+
+        if [ -n "$USER_DATA" ] && [ "$USER_DATA" != "null" ]; then
+            print_success "UserAccount found via GraphQL!"
+            print_json "$USER_DATA"
+
             # データの検証
-            QUERIED_STAFF_NO=$(echo "$STAFF_DATA" | jq -r '.staffNo')
-            if [ "$QUERIED_STAFF_NO" = "$TEST_STAFF_NO" ]; then
-                print_success "Staff No matches: $QUERIED_STAFF_NO"
+            QUERIED_FIRST_NAME=$(echo "$USER_DATA" | jq -r '.firstName')
+            QUERIED_LAST_NAME=$(echo "$USER_DATA" | jq -r '.lastName')
+            QUERIED_USER_ID=$(echo "$USER_DATA" | jq -r '.id')
+
+            if [ "$QUERIED_FIRST_NAME" = "$TEST_FIRST_NAME" ] && [ "$QUERIED_LAST_NAME" = "$TEST_LAST_NAME" ]; then
+                print_success "User data matches: $QUERIED_FIRST_NAME $QUERIED_LAST_NAME"
+
+                # 3.2: Query by ID
+                print_info "Verifying user can be queried by ID: $QUERIED_USER_ID"
+
+                local id_query='query GetUserAccount($id: String!) {
+                    getUserAccount(userAccountId: $id) {
+                        id
+                        firstName
+                        lastName
+                        fullName
+                        createdAt
+                        updatedAt
+                    }
+                }'
+
+                local id_variables="{\"id\": \"$QUERIED_USER_ID\"}"
+
+                ID_RESPONSE=$(execute_graphql "$QUERY_API_ENDPOINT" "$id_query" "$id_variables")
+
+                if echo "$ID_RESPONSE" | jq -e '.data.getUserAccount' > /dev/null 2>&1; then
+                    print_success "UserAccount successfully queried by ID"
+                else
+                    print_error "Failed to query UserAccount by ID"
+                fi
             else
-                print_error "Staff No mismatch! Expected: $TEST_STAFF_NO, Got: $QUERIED_STAFF_NO"
+                print_error "User data mismatch! Expected: $TEST_FIRST_NAME $TEST_LAST_NAME"
             fi
         else
-            print_error "Staff not found in database"
+            print_error "UserAccount not found in database"
             print_info "The event might not have been processed yet"
             return 1
         fi
@@ -214,118 +239,63 @@ query_staff_via_graphql() {
         print_json "$RESPONSE"
         return 1
     fi
-    
-    # 3.2: Query all staff to verify the new staff is in the list
-    print_info "Verifying staff appears in allStaff query..."
-    
-    local all_query='{ 
-        allStaff { 
-            staffNo 
-            globalFamilyName 
-            globalGivenName 
-        } 
-    }'
-    
-    RESPONSE=$(execute_graphql "$all_query")
-    
-    if echo "$RESPONSE" | jq -e '.data.allStaff' > /dev/null 2>&1; then
-        # テストスタッフが含まれているか確認
-        if echo "$RESPONSE" | jq ".data.allStaff[] | select(.staffNo == \"$TEST_STAFF_NO\")" > /dev/null 2>&1; then
-            print_success "Staff appears in allStaff query"
-            TOTAL_COUNT=$(echo "$RESPONSE" | jq '.data.allStaff | length')
-            print_info "Total staff count: $TOTAL_COUNT"
-        else
-            print_error "Staff not found in allStaff query"
-        fi
-    fi
 }
 
 # Step 4: Verify data consistency
 verify_data_consistency() {
     print_header "Step 4: Data Consistency Verification"
-    
-    # 検索クエリでも確認
-    print_info "Searching staff by family name..."
-    
-    local search_query='query SearchStaff($familyName: String) { 
-        searchStaff(globalFamilyName: $familyName) { 
-            staffNo 
-            globalFamilyName 
-            globalGivenName 
-        } 
+
+    print_info "Verifying total user account count..."
+
+    local count_query='{
+        getUserAccounts {
+            id
+        }
     }'
-    
-    local variables="{\"familyName\": \"$TEST_FAMILY_NAME\"}"
-    
-    RESPONSE=$(execute_graphql "$search_query" "$variables")
-    
-    if echo "$RESPONSE" | jq -e '.data.searchStaff' > /dev/null 2>&1; then
-        if echo "$RESPONSE" | jq ".data.searchStaff[] | select(.staffNo == \"$TEST_STAFF_NO\")" > /dev/null 2>&1; then
-            print_success "Staff found via search query"
-        else
-            print_error "Staff not found via search query"
-        fi
-    fi
-}
 
-# オプション: クリーンアップ（退職処理）
-cleanup_test_staff() {
-    print_header "Optional: Cleanup Test Data"
-    print_info "Scheduling retirement for test staff..."
-    
-    # 明日の日付を退職日として設定
-    RETIREMENT_DATE=$(date -v+1d +%Y-%m-%d 2>/dev/null || date -d "+1 day" +%Y-%m-%d)
-    
-    RESPONSE=$(run_grpcurl \
-        -format text \
-        -d "staff_no:\"$TEST_STAFF_NO\" retirement_date:\"$RETIREMENT_DATE\"" \
-        $GRPC_HOST:$GRPC_PORT \
-        io.github.j5ik2o.pcqrses.proto.staff.StaffService/ScheduleRetirementStaff 2>&1) || true
-    
-    echo "$RESPONSE"
-    
-    if echo "$RESPONSE" | grep -q "staff_id:"; then
-        print_success "Test staff retirement scheduled for $RETIREMENT_DATE"
-    else
-        print_info "Could not schedule retirement (this is optional)"
+    RESPONSE=$(execute_graphql "$QUERY_API_ENDPOINT" "$count_query")
+
+    if echo "$RESPONSE" | jq -e '.data.getUserAccounts' > /dev/null 2>&1; then
+        TOTAL_COUNT=$(echo "$RESPONSE" | jq '.data.getUserAccounts | length')
+        print_success "Total user account count: $TOTAL_COUNT"
     fi
 }
 
 # メイン処理
 main() {
-    print_header "End-to-End Test Suite"
-    print_info "Testing flow: gRPC Create → Event Processing → GraphQL Query"
+    print_header "End-to-End Test Suite for UserAccount"
+    print_info "Testing flow: GraphQL Mutation → Event Processing → GraphQL Query"
     print_info "Test ID: $TIMESTAMP"
     echo ""
-    
+
     # ヘルスチェック
     health_check
-    
+
     # E2Eテストの実行
-    if create_staff_via_grpc; then
+    if create_user_account_via_graphql; then
         wait_for_consistency
-        
+
         # リトライロジック付きでクエリを実行
         MAX_RETRIES=$E2E_MAX_RETRIES
         RETRY_COUNT=0
         SUCCESS=false
-        
+
         while [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$SUCCESS" = false ]; do
             if [ $RETRY_COUNT -gt 0 ]; then
                 print_info "Retry attempt $RETRY_COUNT/$MAX_RETRIES... (sleep ${E2E_RETRY_DELAY}s)"
                 sleep "$E2E_RETRY_DELAY"
             fi
-            
-            if query_staff_via_graphql; then
+
+            if query_user_account_via_graphql; then
                 SUCCESS=true
                 verify_data_consistency
             else
                 RETRY_COUNT=$((RETRY_COUNT + 1))
             fi
         done
-        
+
         if [ "$SUCCESS" = false ]; then
-            print_error "Failed to query staff after $MAX_RETRIES retries"
+            print_error "Failed to query user account after $MAX_RETRIES retries"
             print_info "Possible causes:"
             echo "  - Lambda function not deployed or not running"
             echo "  - DynamoDB streams not configured"
@@ -333,20 +303,14 @@ main() {
             exit 1
         fi
     else
-        print_error "Failed to create staff, aborting test"
+        print_error "Failed to create user account, aborting test"
         exit 1
     fi
-    
-    # オプション: クリーンアップ
-    if [ "${CLEANUP:-false}" = "true" ]; then
-        cleanup_test_staff
-    fi
-    
+
     print_header "Test Summary"
     print_success "End-to-End test completed successfully!"
-    print_info "Staff No: $TEST_STAFF_NO was created via gRPC and retrieved via GraphQL"
+    print_info "UserAccount ($TEST_FIRST_NAME $TEST_LAST_NAME) was created via GraphQL and retrieved successfully"
     echo ""
-    print_info "To run cleanup: CLEANUP=true $0"
 }
 
 # スクリプト実行
diff --git a/tools/flyway/seed/V2__insert_staff_test_data.sql b/tools/flyway/seed/V2__insert_staff_test_data.sql.bak
similarity index 100%
rename from tools/flyway/seed/V2__insert_staff_test_data.sql
rename to tools/flyway/seed/V2__insert_staff_test_data.sql.bak

```

## コミット: fe66326

### メッセージ

```
feat: Add scripts to run Claude, Codex, and Gemini with appropriate configurations
```

### 変更されたファイル

- A	scripts/run-claude.sh
- A	scripts/run-codex.sh
- A	scripts/run-gemini.sh

### 変更内容

```diff
commit fe663261dd6c60d4a8492afb87f578bab4321f43
Author: Junichi Kato <j5ik2o@gmail.com>
Date:   Tue Nov 18 11:16:11 2025 +0900

    feat: Add scripts to run Claude, Codex, and Gemini with appropriate configurations

diff --git a/scripts/run-claude.sh b/scripts/run-claude.sh
new file mode 100755
index 0000000..b26770c
--- /dev/null
+++ b/scripts/run-claude.sh
@@ -0,0 +1,6 @@
+#!/bin/bash
+
+SCRIPT_DIR=$(cd "$(dirname "$0")" && pwd)
+REPO_ROOT=$(cd "${SCRIPT_DIR}/.." && pwd)
+
+claude --dangerously-skip-permissions "$@"
diff --git a/scripts/run-codex.sh b/scripts/run-codex.sh
new file mode 100755
index 0000000..c50de5d
--- /dev/null
+++ b/scripts/run-codex.sh
@@ -0,0 +1,7 @@
+#!/bin/bash
+
+SCRIPT_DIR=$(cd "$(dirname "$0")" && pwd)
+REPO_ROOT=$(cd "${SCRIPT_DIR}/.." && pwd)
+
+export CODEX_HOME=${REPO_ROOT}/.codex
+codex --dangerously-bypass-approvals-and-sandbox "$@"
diff --git a/scripts/run-gemini.sh b/scripts/run-gemini.sh
new file mode 100755
index 0000000..a9665a3
--- /dev/null
+++ b/scripts/run-gemini.sh
@@ -0,0 +1,6 @@
+#!/bin/bash
+
+SCRIPT_DIR=$(cd "$(dirname "$0")" && pwd)
+REPO_ROOT=$(cd "${SCRIPT_DIR}/.." && pwd)
+
+gemini --yolo "$@"

```

## コミット: 20adbf3

### メッセージ

```
chore: Update .gitignore to exclude Codex related files
```

### 変更されたファイル

- M	.gitignore

### 変更内容

```diff
commit 20adbf39123660c176a542d6ee756877597de734
Author: Junichi Kato <j5ik2o@gmail.com>
Date:   Tue Nov 18 11:15:28 2025 +0900

    chore: Update .gitignore to exclude Codex related files

diff --git a/.gitignore b/.gitignore
index 5f95204..ec0dfd1 100644
--- a/.gitignore
+++ b/.gitignore
@@ -37,4 +37,10 @@ mise.toml
 
 volume/
 
-.claude/settings.local.json
+/.claude/settings.local.json
+/.codex/sessions/
+/.codex/log/
+/.codex/auth.json
+/.codex/history.jsonl
+/.codex/internal_storage.json
+/.codex/version.json

```

